{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "254np25A5m2c",
        "outputId": "1d6e98f0-4975-45eb-a79c-835a5ac77394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'label'列中有 2 个唯一的取值\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取CSV文件，假设文件名为 'your_file.csv'\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "# 查看前几行数据\n",
        "# print(df.head())\n",
        "# 统计'disease'这一列中有多少个唯一的取值\n",
        "unique_diseases_count = df['label'].nunique()\n",
        "\n",
        "# 输出结果\n",
        "print(f\"'label'列中有 {unique_diseases_count} 个唯一的取值\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaL4zYA_5vbU",
        "outputId": "3b699fc6-a99f-46d3-d2dd-4180c91823d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-84a4fde3eec7>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['label'] = df['label'].replace({'Good': 1, 'Bad': 0})\n"
          ]
        }
      ],
      "source": [
        "# Replacing 'Good' with 1 and 'Bad' with 0 in the 'label' column\n",
        "df['label'] = df['label'].replace({'Good': 1, 'Bad': 0})\n",
        "\n",
        "# Optional: View the first few rows of the updated dataframe\n",
        "# print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hPfx5D5yFp",
        "outputId": "b25e03a7-e863-4e4d-f4ef-8207f6ac04f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "数据集中有 154 个自变量\n"
          ]
        }
      ],
      "source": [
        "# 统计除 'label' 列以外的自变量数量\n",
        "num_features = df.drop(columns=['label']).shape[1]\n",
        "\n",
        "# 输出自变量的数量\n",
        "print(f\"数据集中有 {num_features} 个自变量\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7KxRbMS50rP",
        "outputId": "eb7590cd-022c-4c95-8502-7857a2f39503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "删除后数据集中剩余 85 列\n"
          ]
        }
      ],
      "source": [
        "random_seed = 42\n",
        "# 随机删除70个自变量（不包括label列）\n",
        "columns_to_drop = df.drop(columns=['label']).sample(n=70, axis=1).columns\n",
        "new_dataset_reduced = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# 输出剩余的列数\n",
        "print(f\"删除后数据集中剩余 {new_dataset_reduced.shape[1]} 列\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bha_FjLo54V7",
        "outputId": "88f17ac3-1530-470f-c72c-ad05f8269933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "数据集中有 10459 条数据\n"
          ]
        }
      ],
      "source": [
        "# 查看数据集的行数（即数据条数）\n",
        "num_rows = df.shape[0]\n",
        "\n",
        "# 输出数据条数\n",
        "print(f\"数据集中有 {num_rows} 条数据\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34B_FKAI58Pa",
        "outputId": "7d14e12c-573e-4b2d-cf9b-918f7e09bf36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7665, 0.5334, 0.2774, 0.3332], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1281, 0.2371, 0.5962, 0.7572], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6737, 0.4428, 0.5172, 0.1647], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7314, 0.9185, 0.8341, 0.4208], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4206, 0.1610, 0.2534, 0.4395], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6788, 0.7421, 0.2471, 0.2732], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4551, 0.7939, 0.3989, 0.1274], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3843, 0.3178, 0.5598, 0.3088], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4809, 0.6661, 0.1156, 0.1056])\n",
            "Epoch 1, Train Loss: 5672.7956, Train Accuracy: 0.5018, Test Accuracy: 0.5035, Test F1: 0.5082\n",
            "tensor([0.0627, 0.3498, 0.1008, 0.4848])\n",
            "tensor([0.6509, 0.4931, 0.3002, 0.3081], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7072, 0.2683, 0.7460, 0.0949], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5270, 0.4329, 0.5859, 0.8705], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8348, 0.4294, 0.5565, 0.3376], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7488, 0.1297, 0.6673, 0.6661], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5013, 0.5915, 0.2744, 0.0837], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3203, 0.3998, 0.4195, 0.3713], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9061, 0.5930, 0.1323, 0.8586], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1706, 0.1584, 0.2095, 0.3117])\n",
            "Epoch 2, Train Loss: 5532.0318, Train Accuracy: 0.5446, Test Accuracy: 0.5945, Test F1: 0.5979\n",
            "tensor([0.5737, 0.2871, 0.2576, 0.1043])\n",
            "tensor([0.9386, 0.2170, 0.7223, 0.7323], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1649, 0.7500, 0.0528, 0.4595], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8988, 0.8329, 0.3919, 0.2129], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2050, 0.3082, 0.1402, 0.1132], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4539, 0.7193, 0.0718, 0.4919], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5874, 0.6754, 0.8722, 0.6828], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2558, 0.3768, 0.3907, 0.5835], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4348, 0.4317, 0.6331, 0.4397], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2898, 0.5486, 0.7029, 0.5949])\n",
            "Epoch 3, Train Loss: 5460.2478, Train Accuracy: 0.5653, Test Accuracy: 0.5940, Test F1: 0.6035\n",
            "tensor([0.3991, 0.0748, 0.1177, 0.1508])\n",
            "tensor([0.7915, 0.1730, 0.3144, 0.3855], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6906, 0.4996, 0.3066, 0.1447], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4500, 0.4191, 0.1566, 0.8023], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3984, 0.3823, 0.5704, 0.4047], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6391, 0.7406, 0.7483, 0.2175], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5246, 0.7895, 0.7251, 0.5774], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2147, 0.6939, 0.8472, 0.3419], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6170, 0.7804, 0.7532, 0.0500], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3350, 0.6340, 0.3367, 0.7571])\n",
            "Epoch 4, Train Loss: 5346.0799, Train Accuracy: 0.6066, Test Accuracy: 0.6100, Test F1: 0.6296\n",
            "tensor([0.8002, 0.3151, 0.7219, 0.7759])\n",
            "tensor([0.3943, 0.2782, 0.3228, 0.0711], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5065, 0.5669, 0.3584, 0.7299], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3881, 0.8979, 0.8232, 0.5376], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8190, 0.1648, 0.8569, 0.3568], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1925, 0.7687, 0.8019, 0.5566], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7179, 0.4751, 0.8305, 0.3740], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2954, 0.2500, 0.4991, 0.5855], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5337, 0.7565, 0.4209, 0.9300], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8878, 0.7436, 0.4232, 0.9257])\n",
            "Epoch 5, Train Loss: 5332.7225, Train Accuracy: 0.6011, Test Accuracy: 0.5560, Test F1: 0.6571\n",
            "tensor([0.1383, 0.7933, 0.7643, 0.5709])\n",
            "tensor([0.4991, 0.5097, 0.6058, 0.3621], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7870, 0.9260, 0.8486, 0.9377], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4991, 0.3155, 0.5731, 0.5820], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6281, 0.4183, 0.3856, 0.9123], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9088, 0.2301, 0.3094, 0.0783], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4561, 0.1535, 0.1909, 0.7554], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5222, 0.7185, 0.6841, 0.8039], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8849, 0.4630, 0.2154, 0.4808], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0320, 0.9091, 0.7922, 0.6163])\n",
            "Epoch 6, Train Loss: 5384.2374, Train Accuracy: 0.5907, Test Accuracy: 0.6010, Test F1: 0.5512\n",
            "tensor([0.5073, 0.4599, 0.4685, 0.2294])\n",
            "tensor([0.1528, 0.9251, 0.2749, 0.8263], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3660, 0.3744, 0.6146, 0.7395], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2943, 0.4300, 0.1594, 0.1800], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2123, 0.7813, 0.6859, 0.4589], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7056, 0.9325, 0.3429, 0.1675], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7271, 0.3456, 0.0742, 0.6461], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1641, 0.7884, 0.2294, 0.8307], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0810, 0.5141, 0.8726, 0.1688], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5223, 0.4642, 0.2175, 0.0914])\n",
            "Epoch 7, Train Loss: 5321.3082, Train Accuracy: 0.6116, Test Accuracy: 0.6080, Test F1: 0.6675\n",
            "tensor([0.6093, 0.3929, 0.1328, 0.6304])\n",
            "tensor([0.8646, 0.9115, 0.6566, 0.4628], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3269, 0.1996, 0.2073, 0.4582], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7362, 0.5066, 0.6240, 0.1322], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8747, 0.8984, 0.6943, 0.8497], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9066, 0.3316, 0.1402, 0.2897], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9212, 0.8262, 0.5507, 0.5384], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3438, 0.3550, 0.5353, 0.5857], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5057, 0.0510, 0.4075, 0.0736], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4666, 0.7519, 0.2756, 0.8417])\n",
            "Epoch 8, Train Loss: 5299.5007, Train Accuracy: 0.6104, Test Accuracy: 0.6215, Test F1: 0.6507\n",
            "tensor([0.3056, 0.5410, 0.6050, 0.4046])\n",
            "tensor([0.7600, 0.0745, 0.1005, 0.2022], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2085, 0.2894, 0.4216, 0.4671], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5851, 0.0525, 0.2917, 0.5367], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9570, 0.8751, 0.3970, 0.2330], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0489, 0.2183, 0.6503, 0.6795], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2600, 0.0836, 0.7446, 0.5339], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6958, 0.3366, 0.8090, 0.1041], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2672, 0.5918, 0.6803, 0.4357], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8273, 0.0949, 0.5426, 0.1603])\n",
            "Epoch 9, Train Loss: 5263.2819, Train Accuracy: 0.6268, Test Accuracy: 0.6220, Test F1: 0.6147\n",
            "tensor([0.2421, 0.3370, 0.3022, 0.2247])\n",
            "tensor([0.4979, 0.4973, 0.2697, 0.2330], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9067, 0.6527, 0.3862, 0.3266], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1345, 0.4538, 0.5562, 0.4707], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7750, 0.8227, 0.3885, 0.6535], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1143, 0.7047, 0.1656, 0.2282], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3053, 0.8920, 0.7512, 0.3331], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0696, 0.7301, 0.4156, 0.7282], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4203, 0.4173, 0.2882, 0.8566], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8510, 0.2651, 0.5448, 0.6831])\n",
            "Epoch 10, Train Loss: 5304.5634, Train Accuracy: 0.6102, Test Accuracy: 0.6055, Test F1: 0.5927\n",
            "tensor([0.1802, 0.7211, 0.1868, 0.7716])\n",
            "tensor([0.4069, 0.1484, 0.7348, 0.6807], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7524, 0.4231, 0.7976, 0.5304], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3257, 0.7853, 0.8569, 0.6658], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8957, 0.4307, 0.6933, 0.9040], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9204, 0.7649, 0.4050, 0.7013], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7260, 0.9292, 0.1998, 0.3502], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3757, 0.8141, 0.4943, 0.4307], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7528, 0.4319, 0.6395, 0.8954], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3437, 0.3049, 0.1553, 0.3282])\n",
            "Epoch 11, Train Loss: 5244.0869, Train Accuracy: 0.6298, Test Accuracy: 0.6175, Test F1: 0.5872\n",
            "tensor([0.1974, 0.0639, 0.7758, 0.6833])\n",
            "tensor([0.7930, 0.2716, 0.4595, 0.7307], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8187, 0.6909, 0.6907, 0.3636], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0537, 0.1421, 0.7946, 0.8135], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7053, 0.2524, 0.3016, 0.3982], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2575, 0.3124, 0.5759, 0.6766], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7802, 0.6096, 0.3220, 0.1497], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5680, 0.1779, 0.2040, 0.3891], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7596, 0.2064, 0.6134, 0.7873], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8747, 0.2742, 0.3336, 0.8576])\n",
            "Epoch 12, Train Loss: 5280.3289, Train Accuracy: 0.6215, Test Accuracy: 0.6530, Test F1: 0.5927\n",
            "tensor([0.6966, 0.1139, 0.0775, 0.3853])\n",
            "tensor([0.8812, 0.4380, 0.3763, 0.3059], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5316, 0.1308, 0.2473, 0.5094], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5676, 0.3022, 0.9287, 0.4393], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3773, 0.2387, 0.5911, 0.6450], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0974, 0.5697, 0.7761, 0.6179], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4558, 0.8149, 0.2103, 0.5050], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0525, 0.7060, 0.5104, 0.2071], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2220, 0.1274, 0.7693, 0.3086], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2791, 0.9061, 0.1172, 0.4212])\n",
            "Epoch 13, Train Loss: 5175.4386, Train Accuracy: 0.6431, Test Accuracy: 0.6520, Test F1: 0.5963\n",
            "tensor([0.5087, 0.6296, 0.0657, 0.2899])\n",
            "tensor([0.4092, 0.8226, 0.1862, 0.5033], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2973, 0.7629, 0.8965, 0.6438], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3436, 0.4827, 0.3223, 0.7404], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4313, 0.9366, 0.2071, 0.5865], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5092, 0.7252, 0.6231, 0.4670], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1674, 0.5896, 0.4976, 0.7555], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2471, 0.2910, 0.8683, 0.3818], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5925, 0.8502, 0.9028, 0.8797], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2758, 0.7408, 0.2609, 0.1178])\n",
            "Epoch 14, Train Loss: 5175.3148, Train Accuracy: 0.6446, Test Accuracy: 0.6355, Test F1: 0.6185\n",
            "tensor([0.4548, 0.7724, 0.8471, 0.2874])\n",
            "tensor([0.7854, 0.2120, 0.4508, 0.8452], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6080, 0.1540, 0.6158, 0.1985], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1520, 0.3664, 0.0867, 0.1707], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2524, 0.1388, 0.5086, 0.5062], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6739, 0.2355, 0.1474, 0.2403], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7061, 0.2773, 0.6184, 0.4454], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9297, 0.8067, 0.0529, 0.1642], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6251, 0.2403, 0.1076, 0.5266], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4104, 0.8547, 0.4060, 0.4273])\n",
            "Epoch 15, Train Loss: 5247.0122, Train Accuracy: 0.6191, Test Accuracy: 0.6220, Test F1: 0.5650\n",
            "tensor([0.1457, 0.4733, 0.6337, 0.8122])\n",
            "tensor([0.4295, 0.3399, 0.6398, 0.0674], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8791, 0.4309, 0.1845, 0.2634], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4965, 0.3954, 0.3419, 0.3601], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3538, 0.5035, 0.7800, 0.8373], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7568, 0.3860, 0.2582, 0.1484], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1887, 0.8233, 0.7429, 0.8917], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7414, 0.2861, 0.6479, 0.9252], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3719, 0.1855, 0.9234, 0.6125], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6732, 0.7355, 0.4399, 0.3450])\n",
            "Epoch 16, Train Loss: 5224.7108, Train Accuracy: 0.6302, Test Accuracy: 0.6530, Test F1: 0.6667\n",
            "tensor([0.4646, 0.1040, 0.5101, 0.9253])\n",
            "tensor([0.4043, 0.7301, 0.4942, 0.7384], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1699, 0.3690, 0.8475, 0.2685], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0736, 0.4930, 0.8005, 0.6296], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7007, 0.2554, 0.7450, 0.2269], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3703, 0.8797, 0.7317, 0.1065], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4262, 0.0743, 0.4822, 0.5296], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7849, 0.9097, 0.6326, 0.6385], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7890, 0.5628, 0.4137, 0.6862], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5114, 0.2167, 0.6864, 0.5178])\n",
            "Epoch 17, Train Loss: 5147.2896, Train Accuracy: 0.6522, Test Accuracy: 0.6310, Test F1: 0.6152\n",
            "tensor([0.8662, 0.7948, 0.6155, 0.9320])\n",
            "tensor([0.8590, 0.9112, 0.8892, 0.2609], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2654, 0.1067, 0.8650, 0.6539], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5940, 0.9391, 0.8086, 0.1465], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8831, 0.5060, 0.8256, 0.3495], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8242, 0.4804, 0.0727, 0.2237], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6796, 0.2359, 0.6116, 0.4349], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3503, 0.8490, 0.8791, 0.1481], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3771, 0.3567, 0.0995, 0.0480], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0535, 0.1302, 0.1550, 0.7631])\n",
            "Epoch 18, Train Loss: 5183.9908, Train Accuracy: 0.6364, Test Accuracy: 0.6390, Test F1: 0.6468\n",
            "tensor([0.6990, 0.3322, 0.3101, 0.6842])\n",
            "tensor([0.1094, 0.4568, 0.4002, 0.7210], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2016, 0.4070, 0.8647, 0.5042], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0447, 0.5920, 0.5440, 0.1182], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5623, 0.3366, 0.6997, 0.6615], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3002, 0.3763, 0.4754, 0.2697], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3753, 0.1566, 0.2540, 0.4563], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5756, 0.2670, 0.4810, 0.3084], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7750, 0.3346, 0.6014, 0.8159], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7637, 0.7034, 0.5774, 0.8163])\n",
            "Epoch 19, Train Loss: 5235.9264, Train Accuracy: 0.6272, Test Accuracy: 0.6060, Test F1: 0.5642\n",
            "tensor([0.2619, 0.0886, 0.4272, 0.0711])\n",
            "tensor([0.2021, 0.1085, 0.9286, 0.9183], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1568, 0.5396, 0.2779, 0.7999], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6830, 0.4092, 0.0839, 0.1922], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8576, 0.6170, 0.2583, 0.3051], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1815, 0.2894, 0.2394, 0.2627], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3938, 0.9142, 0.5489, 0.4589], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4049, 0.1780, 0.5078, 0.0515], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5430, 0.5953, 0.5825, 0.4667], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4228, 0.1925, 0.6283, 0.1536])\n",
            "Epoch 20, Train Loss: 5293.4095, Train Accuracy: 0.6106, Test Accuracy: 0.6225, Test F1: 0.6294\n",
            "tensor([0.4959, 0.6522, 0.8392, 0.3762])\n",
            "tensor([0.8394, 0.4299, 0.2316, 0.8869], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0580, 0.0841, 0.3703, 0.4543], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5037, 0.6495, 0.3953, 0.7986], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7357, 0.5796, 0.2010, 0.8387], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5486, 0.1043, 0.5982, 0.2838], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4711, 0.4978, 0.4780, 0.4440], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4851, 0.6472, 0.5284, 0.1296], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3480, 0.7480, 0.6801, 0.2678], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3595, 0.6158, 0.0995, 0.9459])\n",
            "Epoch 21, Train Loss: 5168.0122, Train Accuracy: 0.6408, Test Accuracy: 0.6735, Test F1: 0.6402\n",
            "tensor([0.6928, 0.0956, 0.2738, 0.8307])\n",
            "tensor([0.2450, 0.5636, 0.7574, 0.2884], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7481, 0.8995, 0.7604, 0.7886], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9300, 0.9534, 0.4073, 0.7436], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3646, 0.1892, 0.1726, 0.1730], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4133, 0.8968, 0.6240, 0.1550], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2708, 0.8013, 0.3962, 0.9106], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7726, 0.1822, 0.2910, 0.8171], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4105, 0.1977, 0.5863, 0.6202], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4270, 0.7605, 0.0664, 0.4056])\n",
            "Epoch 22, Train Loss: 5111.8371, Train Accuracy: 0.6510, Test Accuracy: 0.6400, Test F1: 0.6078\n",
            "tensor([0.4026, 0.0587, 0.0520, 0.3129])\n",
            "tensor([0.7570, 0.3462, 0.1117, 0.0831], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2102, 0.8196, 0.8085, 0.2623], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8328, 0.6243, 0.8854, 0.8825], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8771, 0.5092, 0.5512, 0.6617], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0535, 0.1470, 0.8934, 0.2465], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7583, 0.3840, 0.2889, 0.9125], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6649, 0.5246, 0.8908, 0.2471], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3014, 0.3686, 0.0780, 0.5938], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0997, 0.6429, 0.1341, 0.0890])\n",
            "Epoch 23, Train Loss: 5146.3029, Train Accuracy: 0.6396, Test Accuracy: 0.6365, Test F1: 0.6192\n",
            "tensor([0.8606, 0.6126, 0.7199, 0.7707])\n",
            "tensor([0.0654, 0.7139, 0.0491, 0.7655], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0574, 0.6636, 0.4212, 0.3126], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5443, 0.2721, 0.5528, 0.1667], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5134, 0.8240, 0.1883, 0.2507], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6121, 0.1112, 0.5858, 0.5914], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4788, 0.1340, 0.6284, 0.1505], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3701, 0.3664, 0.1617, 0.2746], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7817, 0.6478, 0.6516, 0.4640], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1840, 0.6513, 0.2867, 0.6053])\n",
            "Epoch 24, Train Loss: 5175.0145, Train Accuracy: 0.6391, Test Accuracy: 0.6435, Test F1: 0.6323\n",
            "tensor([0.3467, 0.3518, 0.3714, 0.5231])\n",
            "tensor([0.7685, 0.1629, 0.4614, 0.2175], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7576, 0.4319, 0.7071, 0.1871], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3433, 0.0417, 0.3936, 0.5023], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9081, 0.8668, 0.7409, 0.5022], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4078, 0.1050, 0.6195, 0.3832], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3552, 0.2288, 0.8795, 0.4514], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0503, 0.6360, 0.7275, 0.8775], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1386, 0.9415, 0.2229, 0.4625], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5687, 0.2718, 0.9398, 0.1313])\n",
            "Epoch 25, Train Loss: 5136.4893, Train Accuracy: 0.6444, Test Accuracy: 0.6365, Test F1: 0.6139\n",
            "tensor([0.7104, 0.1996, 0.8568, 0.4281])\n",
            "tensor([0.2766, 0.6886, 0.4555, 0.4516], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5348, 0.6227, 0.4173, 0.2856], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6664, 0.3251, 0.6761, 0.7466], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6178, 0.4061, 0.4429, 0.8534], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1760, 0.0819, 0.1419, 0.0912], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2042, 0.3075, 0.4180, 0.4578], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0824, 0.2792, 0.7085, 0.1451], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1461, 0.9386, 0.7441, 0.4862], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2212, 0.1763, 0.7283, 0.6761])\n",
            "Epoch 26, Train Loss: 5142.2744, Train Accuracy: 0.6464, Test Accuracy: 0.6720, Test F1: 0.6544\n",
            "tensor([0.6452, 0.1997, 0.3544, 0.2924])\n",
            "tensor([0.3760, 0.2526, 0.2626, 0.6898], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1148, 0.1925, 0.9348, 0.5035], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3684, 0.3670, 0.5190, 0.8980], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3193, 0.3368, 0.5736, 0.1741], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0582, 0.7710, 0.6430, 0.3120], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1408, 0.7911, 0.1093, 0.5283], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5018, 0.4501, 0.8818, 0.2762], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4825, 0.4937, 0.2420, 0.7218], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1869, 0.3679, 0.4193, 0.8151])\n",
            "Epoch 27, Train Loss: 5145.8867, Train Accuracy: 0.6431, Test Accuracy: 0.6620, Test F1: 0.6737\n",
            "tensor([0.7181, 0.0821, 0.1752, 0.1020])\n",
            "tensor([0.3969, 0.4566, 0.6014, 0.7818], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4505, 0.9201, 0.8192, 0.5856], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8456, 0.0588, 0.1488, 0.1776], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2145, 0.7344, 0.4020, 0.2688], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6601, 0.8841, 0.0705, 0.2647], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8345, 0.8499, 0.7518, 0.7957], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7105, 0.7798, 0.2561, 0.2634], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1085, 0.7772, 0.6654, 0.6224], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5302, 0.3439, 0.5782, 0.4519])\n",
            "Epoch 28, Train Loss: 5191.4350, Train Accuracy: 0.6380, Test Accuracy: 0.6570, Test F1: 0.6478\n",
            "tensor([0.8312, 0.4887, 0.4699, 0.2319])\n",
            "tensor([0.3219, 0.0827, 0.1478, 0.5964], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6032, 0.4750, 0.0396, 0.2662], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5162, 0.8125, 0.2822, 0.4094], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4808, 0.2906, 0.6004, 0.2755], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6632, 0.4220, 0.1739, 0.7083], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0651, 0.6866, 0.2266, 0.5699], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0935, 0.4574, 0.8186, 0.9249], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2268, 0.9144, 0.2034, 0.2885], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1665, 0.5576, 0.1965, 0.1011])\n",
            "Epoch 29, Train Loss: 5208.6279, Train Accuracy: 0.6355, Test Accuracy: 0.6635, Test F1: 0.6170\n",
            "tensor([0.4899, 0.5526, 0.7993, 0.3582])\n",
            "tensor([0.8642, 0.6816, 0.6393, 0.5064], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6154, 0.7713, 0.7570, 0.9401], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5264, 0.1191, 0.8821, 0.4328], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5710, 0.5439, 0.4928, 0.7762], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2071, 0.6252, 0.4628, 0.2753], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8551, 0.7716, 0.6291, 0.7708], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5083, 0.6770, 0.3889, 0.6216], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5213, 0.8410, 0.4683, 0.0934], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3088, 0.6019, 0.1358, 0.0783])\n",
            "Epoch 30, Train Loss: 5146.8877, Train Accuracy: 0.6485, Test Accuracy: 0.6515, Test F1: 0.6197\n",
            "tensor([0.8985, 0.8616, 0.1521, 0.6098])\n",
            "tensor([0.0645, 0.4581, 0.6971, 0.3185], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6249, 0.6535, 0.8533, 0.7672], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8036, 0.7464, 0.6371, 0.3538], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0943, 0.1855, 0.6096, 0.9317], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6449, 0.6268, 0.9358, 0.0613], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6510, 0.5830, 0.5375, 0.3446], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6267, 0.3614, 0.6757, 0.7454], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1896, 0.4675, 0.7153, 0.0994], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3695, 0.1963, 0.2259, 0.3012])\n",
            "Epoch 31, Train Loss: 5156.3357, Train Accuracy: 0.6492, Test Accuracy: 0.6625, Test F1: 0.6235\n",
            "tensor([0.3673, 0.0898, 0.3898, 0.2511])\n",
            "tensor([0.6761, 0.8823, 0.0857, 0.3315], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4284, 0.7808, 0.0661, 0.5217], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7012, 0.8712, 0.4794, 0.1994], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8612, 0.2213, 0.4494, 0.3138], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4105, 0.8026, 0.6280, 0.1359], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7201, 0.3927, 0.3748, 0.4260], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3575, 0.2907, 0.0635, 0.0934], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8513, 0.8923, 0.4970, 0.8685], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2591, 0.7985, 0.7933, 0.6210])\n",
            "Epoch 32, Train Loss: 5139.6665, Train Accuracy: 0.6454, Test Accuracy: 0.6460, Test F1: 0.6590\n",
            "tensor([0.1012, 0.3789, 0.5142, 0.7953])\n",
            "tensor([0.5050, 0.4182, 0.8078, 0.2670], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4031, 0.4041, 0.8514, 0.3967], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8901, 0.3030, 0.3278, 0.2036], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3167, 0.6996, 0.3811, 0.2694], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5395, 0.5308, 0.2600, 0.4184], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2200, 0.4501, 0.4416, 0.5618], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3695, 0.6177, 0.1335, 0.3653], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6011, 0.3038, 0.5623, 0.3579], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4386, 0.2946, 0.6435, 0.7811])\n",
            "Epoch 33, Train Loss: 5138.4953, Train Accuracy: 0.6482, Test Accuracy: 0.6465, Test F1: 0.6335\n",
            "tensor([0.1049, 0.5930, 0.4838, 0.6607])\n",
            "tensor([0.8622, 0.5341, 0.6483, 0.0561], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2055, 0.6526, 0.5232, 0.8779], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2603, 0.8595, 0.7057, 0.5363], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8438, 0.5222, 0.5499, 0.2538], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5209, 0.7562, 0.7554, 0.2452], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1610, 0.2158, 0.3033, 0.8907], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5659, 0.9287, 0.2710, 0.9026], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8976, 0.8687, 0.7769, 0.7367], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6918, 0.5218, 0.0828, 0.6971])\n",
            "Epoch 34, Train Loss: 5178.4569, Train Accuracy: 0.6400, Test Accuracy: 0.6445, Test F1: 0.6264\n",
            "tensor([0.5482, 0.1645, 0.5126, 0.5687])\n",
            "tensor([0.5854, 0.4583, 0.3450, 0.6437], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1191, 0.3429, 0.2832, 0.5107], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7613, 0.0728, 0.6476, 0.1128], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6271, 0.3852, 0.4367, 0.8507], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5872, 0.8801, 0.7521, 0.1215], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5689, 0.6924, 0.1164, 0.8199], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4498, 0.8341, 0.3005, 0.4049], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9288, 0.8657, 0.3070, 0.3426], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7620, 0.4819, 0.0946, 0.4200])\n",
            "Epoch 35, Train Loss: 5141.6067, Train Accuracy: 0.6485, Test Accuracy: 0.6705, Test F1: 0.6357\n",
            "tensor([0.3619, 0.1358, 0.0337, 0.4524])\n",
            "tensor([0.3798, 0.4281, 0.4210, 0.3491], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5360, 0.1391, 0.0789, 0.1876], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7882, 0.2527, 0.8775, 0.3914], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4437, 0.9199, 0.2310, 0.5463], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8345, 0.1025, 0.5594, 0.2330], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7759, 0.5924, 0.8324, 0.4331], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0413, 0.1239, 0.4837, 0.6508], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7794, 0.7832, 0.2185, 0.4623], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1226, 0.2141, 0.8032, 0.9354])\n",
            "Epoch 36, Train Loss: 5104.3405, Train Accuracy: 0.6520, Test Accuracy: 0.6550, Test F1: 0.6425\n",
            "tensor([0.3937, 0.3397, 0.7839, 0.5405])\n",
            "tensor([0.0397, 0.4142, 0.7624, 0.8773], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7099, 0.5900, 0.4651, 0.9013], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6407, 0.9463, 0.5476, 0.9573], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1035, 0.3156, 0.5870, 0.3348], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1223, 0.6938, 0.3957, 0.5668], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6520, 0.5534, 0.2966, 0.7937], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7444, 0.7439, 0.7159, 0.1797], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5063, 0.8512, 0.4043, 0.3000], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8985, 0.5617, 0.7924, 0.1973])\n",
            "Epoch 37, Train Loss: 5113.5835, Train Accuracy: 0.6562, Test Accuracy: 0.6540, Test F1: 0.6547\n",
            "tensor([0.3466, 0.2256, 0.6041, 0.6779])\n",
            "tensor([0.2115, 0.8710, 0.7064, 0.8084], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1653, 0.4968, 0.5288, 0.9298], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8552, 0.7367, 0.8180, 0.9390], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2660, 0.4061, 0.6087, 0.3437], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7902, 0.3540, 0.9364, 0.5626], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2380, 0.7108, 0.6019, 0.4247], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6579, 0.6517, 0.2555, 0.8459], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6622, 0.9238, 0.0731, 0.3446], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1594, 0.4588, 0.4709, 0.1159])\n",
            "Epoch 38, Train Loss: 5119.9079, Train Accuracy: 0.6499, Test Accuracy: 0.6570, Test F1: 0.6150\n",
            "tensor([0.8328, 0.3086, 0.2759, 0.5546])\n",
            "tensor([0.1391, 0.5362, 0.2399, 0.6186], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7652, 0.2930, 0.3031, 0.1172], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8692, 0.9412, 0.5735, 0.4900], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6144, 0.3638, 0.8677, 0.4203], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8663, 0.6960, 0.6343, 0.4680], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9161, 0.5087, 0.7186, 0.3635], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5094, 0.4863, 0.6079, 0.7999], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7942, 0.2071, 0.8189, 0.6169], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6113, 0.5619, 0.9291, 0.4715])\n",
            "Epoch 39, Train Loss: 5121.8525, Train Accuracy: 0.6518, Test Accuracy: 0.6610, Test F1: 0.6397\n",
            "tensor([0.4405, 0.8306, 0.6820, 0.6634])\n",
            "tensor([0.1078, 0.9110, 0.0604, 0.1486], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1769, 0.5273, 0.1013, 0.8396], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0444, 0.1318, 0.4695, 0.1763], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7243, 0.5732, 0.7254, 0.2430], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7773, 0.8677, 0.5401, 0.7578], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7366, 0.1579, 0.3068, 0.2685], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0985, 0.1093, 0.5490, 0.4942], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5749, 0.0624, 0.2333, 0.1901], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5613, 0.4400, 0.3482, 0.4809])\n",
            "Epoch 40, Train Loss: 5161.9181, Train Accuracy: 0.6484, Test Accuracy: 0.6670, Test F1: 0.6506\n",
            "tensor([0.8271, 0.9261, 0.2328, 0.8017])\n",
            "tensor([0.1528, 0.2202, 0.7965, 0.6918], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2673, 0.6638, 0.1553, 0.3603], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8369, 0.8157, 0.1537, 0.1076], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1896, 0.9342, 0.4613, 0.7526], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0721, 0.1687, 0.4803, 0.7794], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3094, 0.2870, 0.5082, 0.5884], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5549, 0.3684, 0.8664, 0.0968], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8754, 0.2901, 0.8088, 0.4340], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3069, 0.1558, 0.1626, 0.9670])\n",
            "Epoch 41, Train Loss: 5118.5334, Train Accuracy: 0.6593, Test Accuracy: 0.6380, Test F1: 0.6730\n",
            "tensor([0.2614, 0.4682, 0.7249, 0.1620])\n",
            "tensor([0.3947, 0.5189, 0.7477, 0.0535], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5948, 0.5203, 0.1641, 0.2446], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4518, 0.4256, 0.5755, 0.3809], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2208, 0.1033, 0.3008, 0.7845], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7963, 0.2703, 0.1607, 0.2319], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3558, 0.5898, 0.1634, 0.9047], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3375, 0.6961, 0.1130, 0.9452], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3425, 0.7499, 0.6994, 0.0562], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1850, 0.4468, 0.4639, 0.1564])\n",
            "Epoch 42, Train Loss: 5112.7363, Train Accuracy: 0.6502, Test Accuracy: 0.6565, Test F1: 0.6479\n",
            "tensor([0.0967, 0.8817, 0.0749, 0.1108])\n",
            "tensor([0.4926, 0.5564, 0.8096, 0.6919], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1365, 0.6744, 0.7400, 0.3849], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7614, 0.3788, 0.7494, 0.1678], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2676, 0.6817, 0.0838, 0.4622], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1873, 0.3279, 0.1048, 0.8475], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2766, 0.6958, 0.7424, 0.3805], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2524, 0.4660, 0.8915, 0.7210], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2663, 0.2143, 0.6813, 0.0757], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8171, 0.4962, 0.5934, 0.7467])\n",
            "Epoch 43, Train Loss: 5125.4324, Train Accuracy: 0.6539, Test Accuracy: 0.6360, Test F1: 0.6424\n",
            "tensor([0.6269, 0.5538, 0.6743, 0.2708])\n",
            "tensor([0.2957, 0.3007, 0.6911, 0.4581], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1906, 0.3286, 0.7401, 0.2107], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0828, 0.3112, 0.8278, 0.5700], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8608, 0.3722, 0.8722, 0.7144], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3523, 0.6332, 0.7996, 0.3040], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8661, 0.7182, 0.7022, 0.4870], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3844, 0.2226, 0.3362, 0.2092], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6622, 0.1418, 0.8584, 0.4054], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4268, 0.1079, 0.8495, 0.2476])\n",
            "Epoch 44, Train Loss: 5131.6256, Train Accuracy: 0.6478, Test Accuracy: 0.6660, Test F1: 0.6268\n",
            "tensor([0.5554, 0.0975, 0.7924, 0.1775])\n",
            "tensor([0.6988, 0.8108, 0.8899, 0.0792], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8300, 0.9245, 0.6087, 0.1774], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6231, 0.1237, 0.7436, 0.7885], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0757, 0.8956, 0.2513, 0.9266], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4943, 0.8659, 0.2738, 0.8886], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7062, 0.3303, 0.1331, 0.9328], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5523, 0.5900, 0.0601, 0.7377], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6342, 0.8138, 0.2190, 0.8265], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3140, 0.4496, 0.8531, 0.6067])\n",
            "Epoch 45, Train Loss: 5106.4223, Train Accuracy: 0.6531, Test Accuracy: 0.6560, Test F1: 0.6091\n",
            "tensor([0.5446, 0.4565, 0.6001, 0.1060])\n",
            "tensor([0.4503, 0.5372, 0.7501, 0.3423], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6503, 0.5458, 0.2287, 0.7241], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6967, 0.2828, 0.9132, 0.2469], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6502, 0.4252, 0.1032, 0.5766], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2638, 0.5170, 0.7032, 0.5319], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8936, 0.3967, 0.5067, 0.4532], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1061, 0.3905, 0.6815, 0.1883], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6967, 0.5966, 0.2238, 0.1810], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2853, 0.1557, 0.0719, 0.0765])\n",
            "Epoch 46, Train Loss: 5127.3452, Train Accuracy: 0.6466, Test Accuracy: 0.6730, Test F1: 0.6387\n",
            "tensor([0.8602, 0.6409, 0.0844, 0.3473])\n",
            "tensor([0.4755, 0.8579, 0.1260, 0.7196], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2376, 0.6170, 0.6420, 0.7823], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5264, 0.2990, 0.2100, 0.7662], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9240, 0.5420, 0.4836, 0.5737], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8562, 0.1546, 0.2344, 0.6358], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3267, 0.5202, 0.1237, 0.6376], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6920, 0.3178, 0.2144, 0.8586], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2786, 0.1731, 0.2488, 0.7657], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5875, 0.9141, 0.5333, 0.4390])\n",
            "Epoch 47, Train Loss: 5118.3820, Train Accuracy: 0.6526, Test Accuracy: 0.6280, Test F1: 0.6640\n",
            "tensor([0.6949, 0.3604, 0.8106, 0.8134])\n",
            "tensor([0.1731, 0.8503, 0.1436, 0.8472], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6924, 0.3388, 0.8938, 0.4786], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0918, 0.5379, 0.8943, 0.3815], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1606, 0.7352, 0.0888, 0.8136], grad_fn=<SliceBackward0>)\n",
            "tensor([0.1399, 0.3825, 0.4192, 0.0723], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5603, 0.8928, 0.2122, 0.8423], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2562, 0.7490, 0.1193, 0.1297], grad_fn=<SliceBackward0>)\n",
            "tensor([0.4075, 0.8336, 0.6567, 0.7078], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7790, 0.3578, 0.3482, 0.9592])\n",
            "Epoch 48, Train Loss: 5132.8426, Train Accuracy: 0.6459, Test Accuracy: 0.6670, Test F1: 0.6680\n",
            "tensor([0.3280, 0.6865, 0.8994, 0.6470])\n",
            "tensor([0.2027, 0.7614, 0.4756, 0.5733], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3277, 0.6425, 0.4990, 0.9358], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0425, 0.5838, 0.2589, 0.5078], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8846, 0.3652, 0.4327, 0.4097], grad_fn=<SliceBackward0>)\n",
            "tensor([0.3963, 0.8119, 0.1985, 0.9376], grad_fn=<SliceBackward0>)\n",
            "tensor([0.8370, 0.0837, 0.9096, 0.8794], grad_fn=<SliceBackward0>)\n",
            "tensor([0.2446, 0.6766, 0.8469, 0.9327], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5060, 0.2740, 0.5478, 0.7448], grad_fn=<SliceBackward0>)\n",
            "tensor([0.5537, 0.4535, 0.5387, 0.0897])\n",
            "Epoch 49, Train Loss: 5135.5392, Train Accuracy: 0.6481, Test Accuracy: 0.6610, Test F1: 0.6217\n",
            "tensor([0.3351, 0.3259, 0.2584, 0.2461])\n",
            "tensor([0.6633, 0.4355, 0.3375, 0.4104], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7949, 0.6406, 0.0283, 0.3283], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9358, 0.8008, 0.3264, 0.1351], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6967, 0.2280, 0.4155, 0.9305], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7413, 0.8977, 0.8016, 0.1443], grad_fn=<SliceBackward0>)\n",
            "tensor([0.0496, 0.0668, 0.7576, 0.3262], grad_fn=<SliceBackward0>)\n",
            "tensor([0.7053, 0.6657, 0.2092, 0.9112], grad_fn=<SliceBackward0>)\n",
            "tensor([0.9347, 0.2695, 0.2786, 0.8271], grad_fn=<SliceBackward0>)\n",
            "tensor([0.6875, 0.4508, 0.7122, 0.9275])\n",
            "Epoch 50, Train Loss: 5104.3332, Train Accuracy: 0.6558, Test Accuracy: 0.6740, Test F1: 0.6779\n",
            "tensor([0.3231, 0.4089, 0.1966, 0.4842])\n"
          ]
        }
      ],
      "source": [
        "from os import XATTR_CREATE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 设置种子以确保结果可重复\n",
        "# random.seed(45)\n",
        "# torch.manual_seed(45)\n",
        "\n",
        "# 定义嵌入维度 predicate embedding dimension\n",
        "embedding_dim = 8\n",
        "rule_dim = 4\n",
        "latent_num = 4\n",
        "iterations = 10 # default\n",
        "lr = 0.05\n",
        "yrule_dim = 4  # 预测y的rule的数量 default\n",
        "epoch = 50\n",
        "M = 0.9\n",
        "\n",
        "# 获取保留的变量（假设变量名为'variables'，排除'disease'列）\n",
        "variables = [col for col in new_dataset_reduced.columns if col != 'label']\n",
        "\n",
        "# 初始化53个predicate embedding (对于除disease外的53个特征)\n",
        "predicate_embeddings = torch.randn(len(variables), embedding_dim)\n",
        "\n",
        "# 初始化15个latent variable的predicate embedding\n",
        "latent_predicate_embeddings = torch.randn(latent_num, embedding_dim)\n",
        "\n",
        "# 初始化15条rule embedding，每条的维度是3 * embedding_dim\n",
        "rule_embeddings = torch.nn.Parameter(torch.randn(latent_num, rule_dim, embedding_dim, requires_grad=True))\n",
        "\n",
        "# 初始化用于推断y的rule embedding,5条\n",
        "y_rule_embeddings = torch.nn.Parameter(torch.randn(8, rule_dim, embedding_dim, requires_grad=True))\n",
        "\n",
        "# 批次大小\n",
        "batch_size = 1024\n",
        "\n",
        "def softmin(x):\n",
        "    weight = F.softmax(-x, dim=1)\n",
        "    x = torch.sum(weight*x, dim=1)\n",
        "    return x\n",
        "\n",
        "class WeightVector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WeightVector, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.rand(5))  # 初始化为随机值\n",
        "\n",
        "    def forward(self):\n",
        "        return F.softmax(self.weights, dim=0)  # 使用 softmax 函数确保各元素之和为1\n",
        "\n",
        "# 初始化 WeightVector\n",
        "weight_vector = WeightVector()\n",
        "\n",
        "def cosine_similarity_matrix(a, b):\n",
        "    a_expanded = a.unsqueeze(0).expand(b.size(0), -1, -1)\n",
        "    b_expanded = b.unsqueeze(1)\n",
        "    cosine_sim = F.cosine_similarity(a_expanded, b_expanded, dim=2)\n",
        "    cosine_sim = cosine_sim\n",
        "    noise = torch.randn(cosine_sim.size(), device=cosine_sim.device) * 0.0\n",
        "    return cosine_sim + noise\n",
        "\n",
        "def initialize_v_values(samples, latent_predicate_embeddings):\n",
        "    num_samples = samples.size(0)\n",
        "    num_features = samples.size(1)\n",
        "    v_values = torch.zeros(num_samples, num_features + latent_num)\n",
        "    v_values[:, :num_features] = samples\n",
        "    v_values[:, num_features:] = torch.rand(num_samples, latent_predicate_embeddings.size(0))\n",
        "    return v_values\n",
        "\n",
        "def update_latent_v_values(v_values, predicate_embeddings, latent_predicate_embeddings, rule_embeddings, M):\n",
        "    num_samples = v_values.size(0)\n",
        "    combined_embeddings = torch.cat([predicate_embeddings, latent_predicate_embeddings], dim=0)\n",
        "    updated_v_values = torch.zeros(num_samples, len(latent_predicate_embeddings), device=v_values.device)\n",
        "\n",
        "    for i, rule_embedding in enumerate(rule_embeddings):\n",
        "        slot_similarities = []\n",
        "        slot_v_values = []\n",
        "        for slot in rule_embedding:\n",
        "            similarity_matrix = cosine_similarity_matrix(slot, combined_embeddings)\n",
        "            max_similarity, max_index = similarity_matrix.max(dim=0)\n",
        "            slot_similarities.append(max_similarity)\n",
        "            slot_v_values.append(v_values[:, max_index])\n",
        "\n",
        "        slot_similarities = torch.stack(slot_similarities, dim=1)  #[1,3]\n",
        "        slot_similarities_1 = slot_similarities.squeeze(0)\n",
        "        slot_similarities_expand = slot_similarities_1.expand(num_samples, -1)\n",
        "        slot_v_values = torch.stack(slot_v_values, dim=1)\n",
        "        slot_v_values_1 = slot_v_values.squeeze(-1)\n",
        "        combined_1 = torch.cat([slot_similarities_expand, slot_v_values_1], dim=1)\n",
        "        combined = softmin(combined_1)\n",
        "        updated_v_values[:, i] = combined\n",
        "\n",
        "    # 计算加权和\n",
        "    original_latent_v_values = v_values[:, -len(latent_predicate_embeddings):]\n",
        "    weighted_v_values = M * original_latent_v_values + (1 - M) * updated_v_values\n",
        "\n",
        "    # 更新 v_values\n",
        "    new_v_values = v_values.clone()\n",
        "    new_v_values[:, -len(latent_predicate_embeddings):] = weighted_v_values\n",
        "\n",
        "    return new_v_values\n",
        "\n",
        "def infer_latent_variables(samples, predicate_embeddings, latent_predicate_embeddings, rule_embeddings, iterations=iterations):\n",
        "    v_values = initialize_v_values(samples, latent_predicate_embeddings)\n",
        "    for _ in range(iterations):\n",
        "        v_values = update_latent_v_values(v_values, predicate_embeddings, latent_predicate_embeddings, rule_embeddings,M=M)\n",
        "        vector = v_values[0, :]\n",
        "        result = vector[-4:]\n",
        "        print(result)\n",
        "    return v_values\n",
        "\n",
        "def predict_y(v_values, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings):\n",
        "    num_samples = v_values.size(0)\n",
        "    combined_embeddings = torch.cat([predicate_embeddings, latent_predicate_embeddings], dim=0)\n",
        "\n",
        "    A = torch.zeros(num_samples, y_rule_embeddings.size(0), device=v_values.device)\n",
        "    for i, rule_embedding in enumerate(y_rule_embeddings):\n",
        "        similarity_matrix = cosine_similarity_matrix(rule_embedding, combined_embeddings)\n",
        "        max_similarity, max_index = similarity_matrix.max(dim=0)\n",
        "        selected_v_values = v_values[torch.arange(num_samples).unsqueeze(1), max_index]\n",
        "\n",
        "        max_similarity_expanded = max_similarity.unsqueeze(0).expand(num_samples, -1)  # Shape: (64, 3)\n",
        "        combined = torch.cat([max_similarity_expanded, selected_v_values], dim=1)  # Shape: (64, 6)\n",
        "\n",
        "        rule_output = softmin(combined)\n",
        "        A[:, i] = rule_output\n",
        "\n",
        "    weights = F.softmax(A, dim=1)\n",
        "    output = torch.sum(weights * A, dim=1)\n",
        "\n",
        "    return output\n",
        "\n",
        "def compute_loss(v_values, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, labels, lasso_lambda=0.0000001):\n",
        "    y_pred = predict_y(v_values, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings)\n",
        "\n",
        "    labels = labels.float()\n",
        "\n",
        "    loss = F.binary_cross_entropy(y_pred, labels.float())\n",
        "\n",
        "    l1_regularization = lasso_lambda * torch.sum(torch.abs(y_rule_embeddings))\n",
        "\n",
        "    total_loss = loss + l1_regularization\n",
        "\n",
        "    predictions = torch.where(y_pred > 0.5, torch.tensor(1.0), torch.tensor(0.0))\n",
        "    correct = (predictions == labels).sum().item()\n",
        "    accuracy = correct / labels.size(0)\n",
        "\n",
        "    return total_loss, accuracy\n",
        "\n",
        "def evaluate(samples, labels, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, rule_embeddings):\n",
        "    with torch.no_grad():\n",
        "        v_values = infer_latent_variables(samples, predicate_embeddings, latent_predicate_embeddings, rule_embeddings)\n",
        "        y_pred = predict_y(v_values, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings)\n",
        "\n",
        "        predictions = torch.where(y_pred > 0.5, torch.tensor(1.0), torch.tensor(0.0))\n",
        "        correct = (predictions == labels).sum().item()\n",
        "        accuracy = correct / labels.size(0)\n",
        "\n",
        "        # 计算 F1 分数\n",
        "        f1 = f1_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "\n",
        "    return accuracy, f1\n",
        "\n",
        "def train(train_samples, train_labels, test_samples, test_labels, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, rule_embeddings, epochs=epoch, batch_size=batch_size):\n",
        "    optimizer = torch.optim.Adam([y_rule_embeddings, rule_embeddings], lr=lr)\n",
        "\n",
        "    num_samples = train_samples.size(0)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_processed = 0\n",
        "\n",
        "        # Shuffle the training data\n",
        "        permutation = torch.randperm(num_samples)\n",
        "        train_samples = train_samples[permutation]\n",
        "        train_labels = train_labels[permutation]\n",
        "\n",
        "        # Train the model in batches\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_samples = train_samples[i:i+batch_size]\n",
        "            batch_labels = train_labels[i:i+batch_size]\n",
        "            v_values = infer_latent_variables(batch_samples, predicate_embeddings, latent_predicate_embeddings, rule_embeddings)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss, accuracy = compute_loss(v_values, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_samples.size(0)\n",
        "            total_correct += accuracy * batch_samples.size(0)\n",
        "            total_processed += batch_samples.size(0)\n",
        "\n",
        "        # Calculate average loss and accuracy for training set\n",
        "        avg_train_loss = total_loss #/ num_samples\n",
        "        avg_train_accuracy = total_correct / num_samples\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_accuracy, test_f1 = evaluate(test_samples, test_labels, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, rule_embeddings)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1: {test_f1:.4f}')\n",
        "\n",
        "        # Output some y_pred values for debugging (optional)\n",
        "        with torch.no_grad():\n",
        "            v_values_sample = infer_latent_variables(train_samples[:10], predicate_embeddings, latent_predicate_embeddings, rule_embeddings)\n",
        "            y_pred_sample = predict_y(v_values_sample, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings)\n",
        "            # print(\"Sample y_pred values:\", y_pred_sample)\n",
        "\n",
        "# Enable anomaly detection to help locate problems in gradient computation\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# Create train and test sets\n",
        "train_set = new_dataset_reduced.sample(n=8000, random_state=42)\n",
        "test_set = new_dataset_reduced[~new_dataset_reduced.index.isin(train_set.index)].sample(n=2000, random_state=42)\n",
        "\n",
        "# Convert train and test sets to tensors\n",
        "train_samples = torch.tensor(train_set.drop(columns=['label']).values).float()\n",
        "train_labels = torch.tensor(train_set['label'].values).float()\n",
        "\n",
        "test_samples = torch.tensor(test_set.drop(columns=['label']).values).float()\n",
        "test_labels = torch.tensor(test_set['label'].values).float()\n",
        "\n",
        "# Train the model\n",
        "train(train_samples, train_labels, test_samples, test_labels, y_rule_embeddings, predicate_embeddings, latent_predicate_embeddings, rule_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "TWyUqw11BTHf",
        "outputId": "2f71dac8-55d2-4c52-bf61-cca7c26a45ce"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1300x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Re-importing libraries since the environment was reset\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Re-defining the given tensors\n",
        "data = [\n",
        "    torch.tensor([0.8312, 0.4887, 0.4699, 0.2319]),\n",
        "    torch.tensor([0.3219, 0.0827, 0.1478, 0.5964]),\n",
        "    torch.tensor([0.6032, 0.4750, 0.0396, 0.2662]),\n",
        "    torch.tensor([0.5162, 0.8125, 0.2822, 0.4094]),\n",
        "    torch.tensor([0.4808, 0.2906, 0.6004, 0.2755]),\n",
        "    torch.tensor([0.6632, 0.4220, 0.1739, 0.7083]),\n",
        "    torch.tensor([0.0651, 0.6866, 0.2266, 0.5699]),\n",
        "    torch.tensor([0.0935, 0.4574, 0.8186, 0.9249]),\n",
        "    torch.tensor([0.2268, 0.9144, 0.2034, 0.2885]),\n",
        "    torch.tensor([0.1665, 0.5576, 0.1965, 0.1011])\n",
        "]\n",
        "\n",
        "# Combine into a 4x10 matrix\n",
        "matrix = torch.stack(data, dim=1).numpy()\n",
        "\n",
        "# Plotting the heatmap without annotations on the grid cells\n",
        "plt.figure(figsize=(13, 6))\n",
        "\n",
        "# Using a warm color map and keeping the 10 rows by 4 columns structure\n",
        "sns.heatmap(matrix, annot=False, cmap='Oranges', cbar=True)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.title('Heatmap of Latent Values over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Latent Values')\n",
        "\n",
        "# Display the heatmap\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jZYYEUCvQTOv",
        "outputId": "006f7572-516a-4034-a3c5-c8d4a6903f0e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA84AAAIjCAYAAADSuEKwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYIElEQVR4nO3de1xU1f7/8feAznBR8IKCmopiiuYFgzQ0LynFMbPMjqJpIp7sVNKNYyXlEbWSPKZRZtpNLcuii93TUtSstFDMyruWSpmgaN4wQWH//ujnfJuADaPgMM7r+Xjsx2nW3rPXZ29mOH74rLW2xTAMQwAAAAAAoFRerg4AAAAAAIDqjMQZAAAAAAATJM4AAAAAAJggcQYAAAAAwASJMwAAAAAAJkicAQAAAAAwQeIMAAAAAIAJEmcAAAAAAEyQOAMAAAAAYILEGQA8wPTp09WyZUt5e3srIiLC1eFclCwWiyZNmuTqMHCB7dmzRxaLRQsWLHB1KACAKkTiDOCCW7BggSwWi9avX1/q/t69e6t9+/ZVGsOnn37qMUnO559/rgcffFDdu3fX/PnzNXXq1DKPHTVqlGrVqlUp/W7ZskWTJk3Snj17KuV8Zk6ePKlJkyZp1apV5R57zz33yGKxaNeuXWUe88gjj8hiseiHH36oxChRnlWrVsliseidd96xt61Zs0aTJk3SkSNHXBeYpEWLFiktLc2lMQAAXIfEGYBH+vTTTzV58mRXh3FBrFixQl5eXnr55Zc1cuRIXXfddRek3y1btmjy5MkXLHGePHlyhRLn4cOHS/ozESrLG2+8oQ4dOqhjx46VFSLO0Zo1azR58uRqmzg3b95cf/zxh2699dYLHxQA4IIhcQaAi9yBAwfk6+srq9Xq6lCqha5du6pVq1Z64403St2/du1a7d69255go3Ll5+e7OgRJf/6xpTJYLBb5+PjI29u7Us4HAKieSJwBuI3XXntNkZGR8vX1Vb169TR06FD98ssvDsd8+eWXGjx4sJo1ayabzaamTZvq/vvv1x9//GE/ZtSoUZo9e7akP//Re3aT/m++4pNPPqnZs2erZcuW8vPz07XXXqtffvlFhmHo0Ucf1SWXXCJfX1/deOONOnz4sEMMH3zwgfr376/GjRvLZrMpLCxMjz76qIqKihyOOzskPSsrS926dZOvr69atGihuXPnVuh+nDlzRo8++qjCwsJks9kUGhqqhx9+WAUFBfZjLBaL5s+fr/z8fPt1nu9czL179+quu+5SmzZt5Ovrq/r162vw4MEOleUFCxZo8ODBkqSrr77a3vdfK8JLlixRjx495O/vr9q1a6t///7avHmzQ19nh47v27dPAwcOVK1atdSgQQONGzfOfj/37NmjBg0aSJImT55s78tsKP7w4cO1bds2bdiwocS+RYsWyWKxaNiwYSosLNTEiRMVGRmpwMBA+fv7q0ePHlq5cmW592nUqFEKDQ0t0T5p0iT75+2vKvL53rlzp26++WaFhITIx8dHl1xyiYYOHaqjR4+WG8/bb79tP39QUJBGjBihffv22fc/+eSTslgs2rt3b4n3Jicny2q16vfff7e3ffvtt/rHP/6hwMBA+fn5qVevXvr6669LvdYtW7bolltuUd26dXXVVVeVG+tf3//AAw9Iklq0aGH/2f71s1aR+/bX71rPnj3l5+enhx9+WFLFvq+9e/fWJ598or1799pjOPuzLWuO84oVK+yf7zp16ujGG2/U1q1bS70/u3bt0qhRo1SnTh0FBgYqISGhRGK/bNkyXXXVVapTp45q1aqlNm3a2K8BAFD1arg6AACe6+jRo8rLyyvRfvr06RJtjz/+uP773/9qyJAhuu2223Tw4EHNmjVLPXv21Hfffac6depI+jM5OHnypO68807Vr19fmZmZmjVrln799Ve9/fbbkqR///vf+u2337Rs2TItXLiw1Nhef/11FRYW6u6779bhw4f1v//9T0OGDFGfPn20atUqPfTQQ9q1a5dmzZqlcePGad68efb3LliwQLVq1VJSUpJq1aqlFStWaOLEiTp27JimT5/u0M/vv/+u6667TkOGDNGwYcP01ltv6c4775TVatXo0aNN799tt92mV155Rf/85z/1n//8R99++61SU1O1detWvffee5KkhQsX6oUXXlBmZqZeeuklSVK3bt1Mz1uedevWac2aNRo6dKguueQS7dmzR3PmzFHv3r21ZcsW+fn5qWfPnrrnnnv0zDPP6OGHH1bbtm0lyf6/CxcuVHx8vGJjYzVt2jSdPHlSc+bM0VVXXaXvvvvOIeEsKipSbGysunbtqieffFLLly/XjBkzFBYWpjvvvFMNGjTQnDlzdOedd+qmm27SoEGDJMl0mPXw4cM1efJkLVq0SJdffrlDX2+99ZZ69OihZs2aKS8vTy+99JKGDRumMWPG6Pjx43r55ZcVGxurzMzMSltorSKf78LCQsXGxqqgoEB33323QkJCtG/fPn388cc6cuSIAgMDyzz/ggULlJCQoCuuuEKpqanKzc3V008/ra+//tp+/iFDhujBBx/UW2+9ZU9Wz3rrrbd07bXXqm7dupL+TAr79eunyMhIpaSkyMvLS/Pnz1efPn305ZdfqkuXLg7vHzx4sC699FJNnTpVhmFU+L4MGjRIO3bs0BtvvKGnnnpKQUFBkmT/Q0lFfy9I0qFDh9SvXz8NHTpUI0aMUHBwsP3elPd9feSRR3T06FH9+uuveuqppyTJdC2A5cuXq1+/fmrZsqUmTZqkP/74Q7NmzVL37t21YcOGEn9QGTJkiFq0aKHU1FRt2LBBL730kho2bKhp06ZJkjZv3qzrr79eHTt21JQpU2Sz2bRr164Sf6gAAFQhAwAusPnz5xuSTLfLLrvMfvyePXsMb29v4/HHH3c4z48//mjUqFHDof3kyZMl+ktNTTUsFouxd+9ee9vYsWON0n4F7t6925BkNGjQwDhy5Ii9PTk52ZBkdOrUyTh9+rS9fdiwYYbVajVOnTplGsO///1vw8/Pz+G4Xr16GZKMGTNm2NsKCgqMiIgIo2HDhkZhYWHJm/f/bdy40ZBk3HbbbQ7t48aNMyQZK1assLfFx8cb/v7+ZZ7rrypybGnXt3btWkOS8eqrr9rb3n77bUOSsXLlSodjjx8/btSpU8cYM2aMQ3tOTo4RGBjo0B4fH29IMqZMmeJwbOfOnY3IyEj764MHDxqSjJSUlPIu0e6KK64wLrnkEqOoqMjetnTpUkOS8fzzzxuGYRhnzpwxCgoKHN73+++/G8HBwcbo0aMd2v/ef3x8vNG8efMS/aakpDh89ir6+f7uu+8MScbbb79d4Ws0DMMoLCw0GjZsaLRv3974448/7O0ff/yxIcmYOHGivS06OtrhvhqGYWRmZjr8bIuLi41LL73UiI2NNYqLi+3HnTx50mjRooVxzTXXlLjWYcOGVSjWlStXlrjG6dOnG5KM3bt3OxzrzO+Fs9+1uXPnluizot/X/v37l/rzPPs7Y/78+fa2s9/hQ4cO2du+//57w8vLyxg5cqS97ez9+ftn6aabbjLq169vf/3UU08ZkoyDBw+W6B8AcGEwVBuAy8yePVvLli0rsf29Urh48WIVFxdryJAhysvLs28hISG69NJLHYbN+vr62v87Pz9feXl56tatmwzD0HfffVfh2AYPHuxQwevataskacSIEapRo4ZDe2FhocOQ17/GcPz4ceXl5alHjx46efKktm3b5tBPjRo19O9//9v+2mq16t///rcOHDigrKysMuP79NNPJUlJSUkO7f/5z38kSZ988kmFr9VZf72+06dP69ChQ2rVqpXq1KlT6tDnv1u2bJmOHDmiYcOGOfw8vb291bVr11KHQd9xxx0Or3v06KGff/75vK5jxIgR+vXXX7V69Wp726JFi2S1Wu3DzL29ve1zw4uLi3X48GGdOXNGUVFRFbrWiqjo5/vs5/Gzzz5zan7u+vXrdeDAAd11113y8fGxt/fv31/h4eEOn5W4uDhlZWXpp59+srelp6fLZrPpxhtvlCRt3LhRO3fu1C233KJDhw7Z483Pz1ffvn21evVqFRcXO8Tw959fZXDm94Ik2Ww2JSQklDiPM9/Xiti/f782btyoUaNGqV69evb2jh076pprrrF/d/+qtM/3oUOHdOzYMUmyV84/+OCDEvcWAHBhMFQbgMt06dJFUVFRJdrr1q3rMIR7586dMgxDl156aannqVmzpv2/s7OzNXHiRH344YcO8zElVWge6FnNmjVzeH02aWnatGmp7X/ta/PmzZowYYJWrFhh/4dvWTE0btxY/v7+Dm2tW7eW9OfcySuvvLLU+Pbu3SsvLy+1atXKoT0kJER16tQpdZ5qZfnjjz+Umpqq+fPna9++fQ5Dbytyj3fu3ClJ6tOnT6n7AwICHF77+PjYh+aeVbdu3RI/X2cNHTpUSUlJWrRokXr37q1Tp07pvffeU79+/exDkiXplVde0YwZM7Rt2zaHaQQtWrQ4r/7Pqujnu0WLFkpKStLMmTP1+uuvq0ePHrrhhhs0YsQI02HaZz8Lbdq0KbEvPDxcX331lf314MGDlZSUpPT0dD388MMyDENvv/22+vXrZ/+5nP35xcfHl9nn0aNHHe5hZd2rv3Lm94IkNWnSpNQF8pz5vlaE2f1u27atPvvsM+Xn5zt87//+++bsvfv9998VEBCguLg4vfTSS7rttts0fvx49e3bV4MGDdI///lPeXlRAwGAC4HEGUC1V1xcLIvFoiVLlpS6cu3ZuYZFRUW65pprdPjwYT300EMKDw+Xv7+/9u3bp1GjRjlVqSlrhdyy2s8mj0eOHFGvXr0UEBCgKVOmKCwsTD4+PtqwYYMeeuihSq8WlbbIVFW7++67NX/+fN13332Kjo5WYGCgLBaLhg4dWqHrO3vMwoULFRISUmL/Xyv6Utn3/Hw1bNhQ11xzjd59913Nnj1bH330kY4fP+6wmvZrr72mUaNGaeDAgXrggQfUsGFDeXt7KzU11aEqW5qyfjZ/XySuop9vSZoxY4ZGjRqlDz74QJ9//rnuuecepaam6ptvvtEll1zizOWXqnHjxurRo4feeustPfzww/rmm2+UnZ1tn2t7Nl5Jmj59eplzvP8+//evVd3K4sx9KyuGC/19LUt5v1d8fX21evVqrVy5Up988omWLl2q9PR09enTR59//jkregPABUDiDKDaCwsLk2EYatGihb0aW5off/xRO3bs0CuvvKKRI0fa25ctW1bi2KpKOFetWqVDhw5p8eLF6tmzp7199+7dpR7/22+/lag+7dixQ5JKXZH5rObNm6u4uFg7d+60L7glSbm5uTpy5IiaN29+nldStnfeeUfx8fGaMWOGve3UqVMlnrNb1j0OCwuT9GfiGhMTUykxnevPc/jw4Vq6dKmWLFmiRYsWKSAgQAMGDLDvf+edd9SyZUstXrzYoY+UlJRyz123bt1Snz3899EAFf18n9WhQwd16NBBEyZM0Jo1a9S9e3fNnTtXjz32WKnHn/0sbN++vUSVf/v27SU+K3Fxcbrrrru0fft2paeny8/Pz+GenP35BQQEVNrPz4zZ58iZ+1YaZ76vFf2M/fV+/922bdsUFBRUYpRJRXh5ealv377q27evZs6cqalTp+qRRx7RypUrL8jPAQA8HeN7AFR7gwYNkre3tyZPnlxiRV7DMHTo0CFJ/1e1+esxhmHo6aefLnHOs/9wLS2xOR+lxVBYWKjnnnuu1OPPnDmj559/3uHY559/Xg0aNFBkZGSZ/Vx33XWSpLS0NIf2mTNnSvpz/mpV8fb2LvFzmDVrVolKaln3ODY2VgEBAZo6dWqpK6gfPHjQ6Zj8/PxK7as8AwcOlJ+fn5577jktWbJEgwYNcpgHXNrP89tvv9XatWvLPXdYWJiOHj2qH374wd62f/9++4rnZ1X0833s2DGdOXPGYX+HDh3k5eXl8Aiyv4uKilLDhg01d+5ch+OWLFmirVu3lvis3HzzzfL29tYbb7yht99+W9dff71DohcZGamwsDA9+eSTOnHiRIn+zuXnZ6asz1FF75sZZ76v/v7+FRq63ahRI0VEROiVV15xiHnTpk36/PPP7d9dZ/z9kXeS7NV+s589AKDyUHEGUO2FhYXpscceU3Jysvbs2aOBAweqdu3a2r17t9577z3dfvvtGjdunMLDwxUWFqZx48Zp3759CggI0LvvvlvqXNizSek999yj2NhYeXt7a+jQoecda7du3VS3bl3Fx8frnnvukcVi0cKFC8t8BE/jxo01bdo07dmzR61bt1Z6ero2btyoF154ocQczb/q1KmT4uPj9cILL9iHm2ZmZuqVV17RwIEDdfXVV5/zNZw+fbrU6mW9evV011136frrr9fChQsVGBiodu3aae3atVq+fLnq16/vcHxERIS8vb01bdo0HT16VDabTX369FHDhg01Z84c3Xrrrbr88ss1dOhQNWjQQNnZ2frkk0/UvXt3Pfvss07F7Ovrq3bt2ik9PV2tW7dWvXr11L59e7Vv3970fbVq1dLAgQO1aNEiSXIYpi1J119/vRYvXqybbrpJ/fv31+7duzV37ly1a9eu1KTxr4YOHaqHHnpIN910k+655x77I7dat27tsLBYRT/fK1asUGJiogYPHqzWrVvrzJkzWrhwoby9vXXzzTeXGUfNmjU1bdo0JSQkqFevXho2bJj9cVShoaG6//77HY5v2LChrr76as2cOVPHjx9XXFycw34vLy+99NJL6tevny677DIlJCSoSZMm2rdvn1auXKmAgAB99NFHpvfGGWe/q4888oiGDh2qmjVrasCAARW+b2ac+b5GRkYqPT1dSUlJuuKKK1SrVi2HSvxfTZ8+Xf369VN0dLT+9a9/2R9HFRgYaPp88bJMmTJFq1evVv/+/dW8eXMdOHBAzz33nC655BKnnosNADgPF2z9bgD4/84+jmrdunWl7u/Vq5fD46jOevfdd42rrrrK8Pf3N/z9/Y3w8HBj7Nixxvbt2+3HbNmyxYiJiTFq1aplBAUFGWPGjDG+//77Eo+LOXPmjHH33XcbDRo0MCwWi/3xQGcfLTN9+nSHvkt7TE5Z1/L1118bV155peHr62s0btzYePDBB43PPvusxKOZzl7n+vXrjejoaMPHx8do3ry58eyzz1boPp4+fdqYPHmy0aJFC6NmzZpG06ZNjeTkZIdH6BiG84+jUhmPCAsLCzMM48/HMSUkJBhBQUFGrVq1jNjYWGPbtm1G8+bNjfj4eIfzvfjii0bLli0Nb2/vEte/cuVKIzY21ggMDDR8fHyMsLAwY9SoUcb69evLjf3vj3QyDMNYs2aNERkZaVitVqceTfXJJ58YkoxGjRo5PJrKMP589NLUqVON5s2bGzabzejcubPx8ccfl/qoqdL6/Pzzz4327dsbVqvVaNOmjfHaa6+VGrthlP/5/vnnn43Ro0cbYWFhho+Pj1GvXj3j6quvNpYvX16h60xPTzc6d+5s2Gw2o169esbw4cONX3/9tdRjX3zxRUOSUbt2bYdHWP3Vd999ZwwaNMioX7++YbPZjObNmxtDhgwxMjIy7MecvdaKPkaprO/Zo48+ajRp0sTw8vIq8WiqivxeKOt3imFU/Pt64sQJ45ZbbjHq1KljSLL//Et7HJVhGMby5cuN7t27G76+vkZAQIAxYMAAY8uWLQ7HlHV/zv5eOXudGRkZxo033mg0btzYsFqtRuPGjY1hw4YZO3bsqMBdBQBUBothlFEGAQBUqd69eysvL0+bNm1ydSgAAAAwwRxnAAAAAABMkDgDAAAAAGCCxBkAAAAAABPMcQYAAAAAwAQVZwAAAAAATJA4AwAAAABggsQZAAAAAAATNVwdQFUoXvm4q0Nwe5bmV7o6BLdm7P3G1SG4Pa+u/3Z1CG7vmehGrg7BrSU+HO/qENzea08ucHUIbm3EK2+6OgS3V/zRdFeH4PZOHzns6hDcmm/qTleHUGkmhdesunNvO11l564sVJwBAAAAADBxUVacAQAAAACVx+LqAFyMxBkAAAAAYMri4ZkzQ7UBAAAAADBBxRkAAAAAYMrTK66efv0AAAAAAJii4gwAAAAAMMUcZwAAAAAAUCYqzgAAAAAAUx5ecKbiDAAAAACAGSrOAAAAAABTnj7HmcQZAAAAAGDK04cqe/r1AwAAAABgioozAAAAAMCUpw/VpuIMAAAAAHAbs2fPVmhoqHx8fNS1a1dlZmaWeezp06c1ZcoUhYWFycfHR506ddLSpUud7pPEGQAAAABgylKFmzPS09OVlJSklJQUbdiwQZ06dVJsbKwOHDhQ6vETJkzQ888/r1mzZmnLli264447dNNNN+m7775zql8SZwAAAACAW5g5c6bGjBmjhIQEtWvXTnPnzpWfn5/mzZtX6vELFy7Uww8/rOuuu04tW7bUnXfeqeuuu04zZsxwql/mOAMAAAAATFXlHOeCggIVFBQ4tNlsNtlsNoe2wsJCZWVlKTk52d7m5eWlmJgYrV27tsxz+/j4OLT5+vrqq6++cipGKs4AAAAAAJdJTU1VYGCgw5aamlriuLy8PBUVFSk4ONihPTg4WDk5OaWeOzY2VjNnztTOnTtVXFysZcuWafHixdq/f79TMZI4AwAAAABMVeUc5+TkZB09etRh+2tV+Xw8/fTTuvTSSxUeHi6r1arExEQlJCTIy8u5VJjEGQAAAABgystSdZvNZlNAQIDD9vdh2pIUFBQkb29v5ebmOrTn5uYqJCSk1LgbNGig999/X/n5+dq7d6+2bdumWrVqqWXLls5dv1NHAwAAAADgAlarVZGRkcrIyLC3FRcXKyMjQ9HR0abv9fHxUZMmTXTmzBm9++67uvHGG53qm8XBAAAAAACmqnBtMKckJSUpPj5eUVFR6tKli9LS0pSfn6+EhARJ0siRI9WkSRP7HOlvv/1W+/btU0REhPbt26dJkyapuLhYDz74oFP9kjgDAAAAANxCXFycDh48qIkTJyonJ0cRERFaunSpfcGw7Oxsh/nLp06d0oQJE/Tzzz+rVq1auu6667Rw4ULVqVPHqX5JnAEAAAAApqrycVTOSkxMVGJiYqn7Vq1a5fC6V69e2rJly3n3yRxnAAAAAABMUHEGAAAAAJiqRgVnl6DiDAAAAACACSrOAAAAAABTXhbD1SG4FIkzAAAAAMAUQ7UBAAAAAECZqDgDAAAAAExRcQYAAAAAAGWi4gwAAAAAMGXx8JIzFWcAAAAAAExQcQYAAAAAmPLwgjMVZwAAAAAAzFBxBgAAAACY8vLwkjOJMwAAAADAlIfnzQzVBgAAAADADBVnAAAAAIApHkcFAAAAAADKRMUZAAAAAGDKwwvOVJwBAAAAADBDxRkAAAAAYMrTH0dFxRkAAAAAABNUnAEAAAAApjy84EziDAAAAAAwx+OoAAAAAABAmag4AwAAAABMeXjBmYozAAAAAABmqDgDAAAAAEwxxxkAAAAAAJSJijMAAAAAwJSnV1xdmjjn5eVp3rx5Wrt2rXJyciRJISEh6tatm0aNGqUGDRq4MjwAAAAAAFz3h4N169apdevWeuaZZxQYGKiePXuqZ8+eCgwM1DPPPKPw8HCtX7++3PMUFBTo2LFjDltB4ZkLcAUAAAAA4Bkslqrb3IHLKs533323Bg8erLlz58ryt7tlGIbuuOMO3X333Vq7dq3peVJTUzV58mSHtokjr1bKqL6VHjMAAAAAeCI3yW+rjMsqzt9//73uv//+EkmzJFksFt1///3auHFjuedJTk7W0aNHHbbxt/SqgogBAAAAAJ7IZRXnkJAQZWZmKjw8vNT9mZmZCg4OLvc8NptNNpvNoa3YyppnAAAAAFBZvDy85OyyDHPcuHG6/fbblZWVpb59+9qT5NzcXGVkZOjFF1/Uk08+6arwAAAAAACQ5MLEeezYsQoKCtJTTz2l5557TkVFRZIkb29vRUZGasGCBRoyZIirwgMAAAAA/H8eXnB27eOo4uLiFBcXp9OnTysvL0+SFBQUpJo1a7oyLAAAAAAA7KrFZOCaNWuqUaNGrg4DAAAAAFAKT5/j7LJVtQEAAAAAcAfVouIMAAAAAKi+PL3iSuIMAAAAADBlYag2AAAAAADuYfbs2QoNDZWPj4+6du2qzMxM0+PT0tLUpk0b+fr6qmnTprr//vt16tQpp/okcQYAAAAAmPKqws0Z6enpSkpKUkpKijZs2KBOnTopNjZWBw4cKPX4RYsWafz48UpJSdHWrVv18ssvKz09XQ8//LBT/ZI4AwAAAADcwsyZMzVmzBglJCSoXbt2mjt3rvz8/DRv3rxSj1+zZo26d++uW265RaGhobr22ms1bNiwcqvUf0fiDAAAAAAwZbFU3VZQUKBjx445bAUFBSViKCwsVFZWlmJiYuxtXl5eiomJ0dq1a0uNu1u3bsrKyrInyj///LM+/fRTXXfddU5dP4kzAAAAAMBlUlNTFRgY6LClpqaWOC4vL09FRUUKDg52aA8ODlZOTk6p577llls0ZcoUXXXVVapZs6bCwsLUu3dvhmoDAAAAACqXl8Wosi05OVlHjx512JKTkysl7lWrVmnq1Kl67rnntGHDBi1evFiffPKJHn30UafOw+OoAAAAAAAuY7PZZLPZyj0uKChI3t7eys3NdWjPzc1VSEhIqe/573//q1tvvVW33XabJKlDhw7Kz8/X7bffrkceeUReXhWrJVNxBgAAAACYqg6ralutVkVGRiojI8PeVlxcrIyMDEVHR5f6npMnT5ZIjr29vSVJhmFUuG8qzgAAAAAAt5CUlKT4+HhFRUWpS5cuSktLU35+vhISEiRJI0eOVJMmTexzpAcMGKCZM2eqc+fO6tq1q3bt2qX//ve/GjBggD2BrggSZwAAAACAKYvF1RH8KS4uTgcPHtTEiROVk5OjiIgILV261L5gWHZ2tkOFecKECbJYLJowYYL27dunBg0aaMCAAXr88ced6pfEGQAAAABgqjrN8U1MTFRiYmKp+1atWuXwukaNGkpJSVFKSsp59Vmdrh8AAAAAgGqHijMAAAAAwFR1GartKlScAQAAAAAwQcUZAAAAAGDK0yuunn79AAAAAACYouIMAAAAADDlxRxnAAAAAABQFirOAAAAAABTnr6qNokzAAAAAMCUpw9V9vTrBwAAAADAFBVnAAAAAIApTx+qTcUZAAAAAAATVJwBAAAAAKY8veLq6dcPAAAAAIApKs4AAAAAAFNezHEGAAAAAABloeIMAAAAADDl4QVnEmcAAAAAgDmGagMAAAAAgDJRcQYAAAAAmPLwgjMVZwAAAAAAzFBxBgAAAACYYo4zAAAAAAAoExVnAAAAAIApL4vh6hBcioozAAAAAAAmqDgDAAAAAEx5+BRnEmcAAAAAgDkWBwMAAAAAAGWi4gwAAAAAMOXhBWcqzgAAAAAAmKHiDAAAAAAwxRxnAAAAAABQJirOAAAAAABTnl5x9fTrBwAAAADAFBVnAAAAAIApi4fPcSZxBgAAAACYYnEwAAAAAABQJothGIarg6hsu2+yujoEt7fvSJGrQ3Brlzb1c3UIbs+/XoCrQ3B7fn3jXB2CW1s89RlXh+D2/rn0Z1eH4Nay/9Xa1SG4vUsemePqENxf5ruujsCtef37Y1eHUGl29Ku6mmvrJcVVdu7KQsUZAAAAAAATzHEGAAAAAJiyePjqYFScAQAAAABuY/bs2QoNDZWPj4+6du2qzMzMMo/t3bu3LBZLia1///5O9UniDAAAAAAwZbFU3eaM9PR0JSUlKSUlRRs2bFCnTp0UGxurAwcOlHr84sWLtX//fvu2adMmeXt7a/DgwU71S+IMAAAAAHALM2fO1JgxY5SQkKB27dpp7ty58vPz07x580o9vl69egoJCbFvy5Ytk5+fn9OJM3OcAQAAAADmqnCOc0FBgQoKChzabDabbDabQ1thYaGysrKUnJxsb/Py8lJMTIzWrl1bob5efvllDR06VP7+/k7FSMUZAAAAAGCqKodqp6amKjAw0GFLTU0tEUNeXp6KiooUHBzs0B4cHKycnJxyryEzM1ObNm3Sbbfd5vT1U3EGAAAAALhMcnKykpKSHNr+Xm2uDC+//LI6dOigLl26OP1eEmcAAAAAgKmqfBxVacOySxMUFCRvb2/l5uY6tOfm5iokJMT0vfn5+XrzzTc1ZcqUc4qRodoAAAAAgGrParUqMjJSGRkZ9rbi4mJlZGQoOjra9L1vv/22CgoKNGLEiHPqm4ozAAAAAMBUVVacnZGUlKT4+HhFRUWpS5cuSktLU35+vhISEiRJI0eOVJMmTUrMkX755Zc1cOBA1a9f/5z6JXEGAAAAALiFuLg4HTx4UBMnTlROTo4iIiK0dOlS+4Jh2dnZ8vJyHFi9fft2ffXVV/r888/PuV8SZwAAAACAuWo0yTcxMVGJiYml7lu1alWJtjZt2sgwjPPqsxpdPgAAAAAA1Q8VZwAAAACAqeoyx9lVSJwBAAAAAKY8PG9mqDYAAAAAAGaoOAMAAAAATHn6UG0qzgAAAAAAmKDiDAAAAAAw59kFZyrOAAAAAACYoeIMAAAAADDFHGcAAAAAAFAmKs4AAAAAAFMeXnAmcQYAAAAAmGOoNgAAAAAAKBMVZwAAAACAOSrOAAAAAACgLFScAQAAAACmPLzgTMUZAAAAAAAzVJwBAAAAAKZYVRsAAAAAAJSJijMAAAAAwJSHF5ypOAMAAAAAYIaKMwAAAADAnIeXnEmcAQAAAACmPDxvZqg2AAAAAABmqDgDAAAAAEzxOCoAAAAAAFAmKs4AAAAAAFNUnAEAAAAAQJmoOAMAAAAATHl4wZmKMwAAAAAAZqg4AwAAAADMeXjJmcQZAAAAAGDKw/NmhmoDAAAAAGCGijMAAAAAwBSPowIAAAAAAGWi4gwAAAAAMOXhBWcqzgAAAAAAmKHiDAAAAAAw5+ElZyrOAAAAAACYoOIMAAAAADDl6atqkzgDAAAAAEx5eN7MUG0AAAAAgPuYPXu2QkND5ePjo65duyozM9P0+CNHjmjs2LFq1KiRbDabWrdurU8//dSpPqk4AwAAAABMVZeh2unp6UpKStLcuXPVtWtXpaWlKTY2Vtu3b1fDhg1LHF9YWKhrrrlGDRs21DvvvKMmTZpo7969qlOnjlP9VuuK8y+//KLRo0ebHlNQUKBjx445bAVFxgWKEAAAAABwocycOVNjxoxRQkKC2rVrp7lz58rPz0/z5s0r9fh58+bp8OHDev/999W9e3eFhoaqV69e6tSpk1P9VuvE+fDhw3rllVdMj0lNTVVgYKDDNmdH8QWKEAAAAAA8gKXqtlKLoQUFJUIoLCxUVlaWYmJi7G1eXl6KiYnR2rVrSw37ww8/VHR0tMaOHavg4GC1b99eU6dOVVFRkVOX79Kh2h9++KHp/p9//rnccyQnJyspKcmh7bcR9c8rLgAAAADAhZGamqrJkyc7tKWkpGjSpEkObXl5eSoqKlJwcLBDe3BwsLZt21bquX/++WetWLFCw4cP16effqpdu3bprrvu0unTp5WSklLhGF2aOA8cOFAWi0WGUfbQ6vLG0ttsNtlsNoe2Q97VY/w9AAAAAFwMLF5VN1i5tGLo33O8c1VcXKyGDRvqhRdekLe3tyIjI7Vv3z5Nnz7dqcTZpUO1GzVqpMWLF6u4uLjUbcOGDa4MDwAAAABQxWw2mwICAhy20hLnoKAgeXt7Kzc316E9NzdXISEhpZ67UaNGat26tby9ve1tbdu2VU5OjgoLCysco0sT58jISGVlZZW5v7xqNAAAAADgArBYqm6rIKvVqsjISGVkZNjbiouLlZGRoejo6FLf0717d+3atUvFxf+3DtaOHTvUqFEjWa3WCvft0sT5gQceULdu3crc36pVK61cufICRgQAAAAAKKEaJM6SlJSUpBdffFGvvPKKtm7dqjvvvFP5+flKSEiQJI0cOVLJycn24++8804dPnxY9957r3bs2KFPPvlEU6dO1dixY53q16VznHv06GG639/fX7169bpA0QAAAAAAqrO4uDgdPHhQEydOVE5OjiIiIrR06VL7gmHZ2dny+st87KZNm+qzzz7T/fffr44dO6pJkya699579dBDDznVr0sTZwAAAABA9WexVJ8nGScmJioxMbHUfatWrSrRFh0drW+++ea8+qw+Vw8AAAAAQDVExRkAAAAAYM7JucgXGyrOAAAAAACYoOIMAAAAADBHxdk5v/zyi3799Vf768zMTN1333164YUXKjUwAAAAAACqA6cT51tuucX+bOWcnBxdc801yszM1COPPKIpU6ZUeoAAAAAAANeyWCxVtrkDpxPnTZs2qUuXLpKkt956S+3bt9eaNWv0+uuva8GCBZUdHwAAAADA1SxeVbe5AaejPH36tGw2myRp+fLluuGGGyRJ4eHh2r9/f+VGBwAAAACAizmdOF922WWaO3euvvzySy1btkz/+Mc/JEm//fab6tevX+kBAgAAAABcy+JlqbLNHTidOE+bNk3PP/+8evfurWHDhqlTp06SpA8//NA+hBsAAAAAgIuF04+j6t27t/Ly8nTs2DHVrVvX3n777bfLz8+vUoMDAAAAAFQDbrKIV1U5p5nYhmEoKytLzz//vI4fPy5JslqtJM4AAAAAgIuO0xXnvXv36h//+Ieys7NVUFCga665RrVr19a0adNUUFCguXPnVkWcAAAAAABXcZPVr6uK01d/7733KioqSr///rt8fX3t7TfddJMyMjIqNTgAAAAAAFzN6Yrzl19+qTVr1shqtTq0h4aGat++fZUWGAAAAACgerB4+BxnpxPn4uJiFRUVlWj/9ddfVbt27UoJCgAAAABQjXh44uz0UO1rr71WaWlp9tcWi0UnTpxQSkqKrrvuusqMDQAAAAAAl3O64jxjxgzFxsaqXbt2OnXqlG655Rbt3LlTQUFBeuONN6oiRgAAAACAK3l4xdnpxPmSSy7R999/rzfffFM//PCDTpw4oX/9618aPny4w2JhAAAAAABcDJxOnCWpRo0aGjFiRGXHAgAAAACohiwe/jgqpxPnV1991XT/yJEjzzkYAAAAAACqG6cT53vvvdfh9enTp3Xy5ElZrVb5+fmROAMAAADAxcbD5zg7XW///fffHbYTJ05o+/btuuqqq1gcDAAAAABw0TmnOc5/d+mll+qJJ57QiBEjtG3btso4JQAAAACgmrB4eXbFuVISZ+nPBcN+++23yjodAAAAAKC6YHEw53z44YcOrw3D0P79+/Xss8+qe/fulRYYAAAAAADVgdOJ88CBAx1eWywWNWjQQH369NGMGTMqKy4AAAAAQHXh4YuDOZ04FxcXV0UcAAAAAABUS5U2xxkAAAAAcHGyUHEuX1JSUoVPOHPmzHMOBgAAAACA6qZCifN3331XoZN5+l8hAAAAAOCi5OG5XoUS55UrV1Z1HAAAAAAAVEvMcQYAAAAAmOM5zs5bv3693nrrLWVnZ6uwsNBh3+LFiyslMAAAAABA9eDp03Kd/rPBm2++qW7dumnr1q167733dPr0aW3evFkrVqxQYGBgVcQIAAAAAIDLOJ04T506VU899ZQ++ugjWa1WPf3009q2bZuGDBmiZs2aVUWMAAAAAABX8rJU3eYGnE6cf/rpJ/Xv31+SZLValZ+fL4vFovvvv18vvPBCpQcIAAAAAIArOZ04161bV8ePH5ckNWnSRJs2bZIkHTlyRCdPnqzc6AAAAAAALmexeFXZ5g6cXhysZ8+eWrZsmTp06KDBgwfr3nvv1YoVK7Rs2TL17du3KmIEAAAAAMBlKpw4b9q0Se3bt9ezzz6rU6dOSZIeeeQR1axZU2vWrNHNN9+sCRMmVFmgAAAAAAAX8fBVtSucOHfs2FFXXHGFbrvtNg0dOlSS5OXlpfHjx1dZcAAAAAAAuFqFB5R/8cUXuuyyy/Sf//xHjRo1Unx8vL788suqjA0AAAAAUB1YLFW3OWn27NkKDQ2Vj4+PunbtqszMzDKPXbBggSwWi8Pm4+PjdJ8VTpx79OihefPmaf/+/Zo1a5b27NmjXr16qXXr1po2bZpycnKc7hwAAAAAgIpKT09XUlKSUlJStGHDBnXq1EmxsbE6cOBAme8JCAjQ/v377dvevXud7tfpJcz8/f2VkJCgL774Qjt27NDgwYM1e/ZsNWvWTDfccIPTAQAAAAAAqre/V20rc3PGzJkzNWbMGCUkJKhdu3aaO3eu/Pz8NG/ePNPYQ0JC7FtwcLDT139ea3+3atVKDz/8sCZMmKDatWvrk08+OZ/TAQAAAACqI4tXlW0FBQU6duyYw1ZQUFAihMLCQmVlZSkmJsbe5uXlpZiYGK1du7bM0E+cOKHmzZuradOmuvHGG7V582anL/+cE+fVq1dr1KhRCgkJ0QMPPKBBgwbp66+/PtfTAQAAAAA8UGpqqgIDAx221NTUEsfl5eWpqKioRMU4ODi4zKnDbdq00bx58/TBBx/otddeU3Fxsbp166Zff/3VqRideo7zb7/9pgULFmjBggXatWuXunXrpmeeeUZDhgyRv7+/Ux0DAAAAANxEFT6OKjk5WUlJSQ5tNputUs4dHR2t6Oho++tu3bqpbdu2ev755/Xoo49W+DwVTpz79eun5cuXKygoSCNHjtTo0aPVpk0b56IGAAAAAOAvbDZbhRLloKAgeXt7Kzc316E9NzdXISEhFeqrZs2a6ty5s3bt2uVUjBUeql2zZk298847+vXXXzVt2jSSZgAAAADwENVhcTCr1arIyEhlZGTY24qLi5WRkeFQVTZTVFSkH3/8UY0aNXLq+itccf7www+dOjEAAAAAAJUpKSlJ8fHxioqKUpcuXZSWlqb8/HwlJCRIkkaOHKkmTZrY50hPmTJFV155pVq1aqUjR45o+vTp2rt3r2677Tan+nVqjrO7eHeX4eoQ3F7S7Ve7OgS3Zpw66eoQ3J7lH3e7OgT3t36xqyNwazcv+tzVIbi9/3UPc3UIbq2BD/+eOV/D3pnm6hDcnqXGRZkuXDCVM0u3mvA6rwcyVZq4uDgdPHhQEydOVE5OjiIiIrR06VL7gmHZ2dny+kusv//+u8aMGaOcnBzVrVtXkZGRWrNmjdq1a+dUv3wTAAAAAABuIzExUYmJiaXuW7VqlcPrp556Sk899dR590niDAAAAAAwV4WrarsDp+vtq1ev1pkzZ0q0nzlzRqtXr66UoAAAAAAA1YjFq+o2N+B0lFdffbUOHz5cov3o0aO6+mrmxQIAAAAALi5OD9U2DKPUJcMPHTokf3//SgkKAAAAAFCNePhQ7QonzoMGDZL05/O7Ro0a5fCA6qKiIv3www/q1q1b5UcIAAAAAIALVThxDgwMlPRnxbl27dry9fW177Narbryyis1ZsyYyo8QAAAAAOBabjIXuapUOHGeP3++JCk0NFTjxo1jWDYAAAAAwCM4Pcc5JSWlKuIAAAAAAFRXHj7H2el6e25urm699VY1btxYNWrUkLe3t8MGAAAAAMDFxOmK86hRo5Sdna3//ve/atSoUakrbAMAAAAALiLMcXbOV199pS+//FIRERFVEA4AAAAAoNrx8IKp0382aNq0qQzDqIpYAAAAAACodpxOnNPS0jR+/Hjt2bOnCsIBAAAAAFQ7Fq+q29yA00O14+LidPLkSYWFhcnPz081a9Z02H/48OFKCw4AAAAAAFdzOnFOS0urgjAAAAAAANWWh89xdjpxjo+Pr4o4AAAAAACols5pQPlPP/2kCRMmaNiwYTpw4IAkacmSJdq8eXOlBgcAAAAAqAYslqrb3IDTifMXX3yhDh066Ntvv9XixYt14sQJSdL333+vlJSUSg8QAAAAAABXcjpxHj9+vB577DEtW7ZMVqvV3t6nTx998803lRocAAAAAKAaYFVt5/z4449atGhRifaGDRsqLy+vUoICAAAAAFQjbjKkuqo4nd7XqVNH+/fvL9H+3XffqUmTJpUSFAAAAAAA1YXTifPQoUP10EMPKScnRxaLRcXFxfr66681btw4jRw5sipiBAAAAAC4kocP1XY6yqlTpyo8PFxNmzbViRMn1K5dO/Xs2VPdunXThAkTqiJGAAAAAABcxuk5zlarVS+++KImTpyoH3/8USdOnFDnzp116aWXVkV8AAAAAABXY46zc6ZMmaKTJ0+qadOmuu666zRkyBBdeuml+uOPPzRlypSqiBEAAAAAAJdxOnGePHmy/dnNf3Xy5ElNnjy5UoICAAAAAFQjzHF2jmEYspRSpv/+++9Vr169SgkKAAAAAIDqosJznOvWrSuLxSKLxaLWrVs7JM9FRUU6ceKE7rjjjioJEgAAAADgQh4+x7nCiXNaWpoMw9Do0aM1efJkBQYG2vdZrVaFhoYqOjq6SoIEAAAAALiQmwyprioVTpzj4+MlSS1atFC3bt1Us2bNKgsKAAAAAIDqwunHUfXq1cv+36dOnVJhYaHD/oCAgPOPCgAAAABQfXj4UG2n6+0nT55UYmKiGjZsKH9/f9WtW9dhAwAAAADgYuJ04vzAAw9oxYoVmjNnjmw2m1566SVNnjxZjRs31quvvloVMQIAAAAAXMnDH0fl9FDtjz76SK+++qp69+6thIQE9ejRQ61atVLz5s31+uuva/jw4VURJwAAAAAALuF0en/48GG1bNlS0p/zmQ8fPixJuuqqq7R69erKjQ4AAAAA4HoWS9VtbsDpxLlly5bavXu3JCk8PFxvvfWWpD8r0XXq1KnU4AAAAAAAcDWnE+eEhAR9//33kqTx48dr9uzZ8vHx0f33368HHnig0gMEAAAAALgYc5ydc//999v/OyYmRtu2bVNWVpZatWqljh07VmpwAAAAAIBqwE2GVFeV807vmzdvrkGDBqlevXq6/fbbKyMmAAAAAACqjUqrix86dEgvv/xyZZ0OAAAAAFBdePhQbfeIEgAAAAAASbNnz1ZoaKh8fHzUtWtXZWZmVuh9b775piwWiwYOHOh0nyTOAAAAAABz1eRxVOnp6UpKSlJKSoo2bNigTp06KTY2VgcOHDB93549ezRu3Dj16NHjnC6fxBkAAAAA4BZmzpypMWPGKCEhQe3atdPcuXPl5+enefPmlfmeoqIiDR8+XJMnT1bLli3Pqd8Kr6o9aNAg0/1Hjhw5pwAAAAAAANVcFc5FLigoUEFBgUObzWaTzWZzaCssLFRWVpaSk5PtbV5eXoqJidHatWvLPP+UKVPUsGFD/etf/9KXX355TjFW+OoDAwNNt+bNm2vkyJHnFAQAAAAAwDOlpqaWyC9TU1NLHJeXl6eioiIFBwc7tAcHBysnJ6fUc3/11Vd6+eWX9eKLL55XjBWuOM+fP/+8OgIAAAAAuKkqfI5zcnKykpKSHNr+Xm0+F8ePH9ett96qF198UUFBQed1rgonzgAAAAAAD1WFQ7VLG5ZdmqCgIHl7eys3N9ehPTc3VyEhISWO/+mnn7Rnzx4NGDDA3lZcXCxJqlGjhrZv366wsLAKxcjiYAAAAACAas9qtSoyMlIZGRn2tuLiYmVkZCg6OrrE8eHh4frxxx+1ceNG+3bDDTfo6quv1saNG9W0adMK903FGQAAAABgzqvqhmo7IykpSfHx8YqKilKXLl2Ulpam/Px8JSQkSJJGjhypJk2aKDU1VT4+Pmrfvr3D++vUqSNJJdrLQ+IMAAAAAHALcXFxOnjwoCZOnKicnBxFRERo6dKl9gXDsrOz5eVV+QOrSZwBAAAAAOaqcHEwZyUmJioxMbHUfatWrTJ974IFC86pT+Y4AwAAAABggoozAAAAAMBcFa6q7Q48++oBAAAAACiHyxPnP/74Q1999ZW2bNlSYt+pU6f06quvmr6/oKBAx44dc9jOFBtVFS4AAAAAeB6Lpeo2N+DSxHnHjh1q27atevbsqQ4dOqhXr17av3+/ff/Ro0fty4qXJTU1VYGBgQ7bioPFVR06AAAAAHgOi1fVbW7ApVE+9NBDat++vQ4cOKDt27erdu3a6t69u7Kzsyt8juTkZB09etRh69PAPW4+AAAAAKD6c+niYGvWrNHy5csVFBSkoKAgffTRR7rrrrvUo0cPrVy5Uv7+/uWew2azyWazObTVqCYP5wYAAACAi4KbVIarikuv/o8//lCNGv+Xu1ssFs2ZM0cDBgxQr169tGPHDhdGBwAAAACAiyvO4eHhWr9+vdq2bevQ/uyzz0qSbrjhBleEBQAAAAD4KyrOrnPTTTfpjTfeKHXfs88+q2HDhskwWCEbAAAAAOA6Lk2ck5OT9emnn5a5/7nnnlNxMStkAwAAAIBL8TgqAAAAAABQFpfOcQYAAAAAuAEPn+NM4gwAAAAAMOfhibNnXz0AAAAAAOWg4gwAAAAAMOcmi3hVFSrOAAAAAACYoOIMAAAAADDHHGcAAAAAAFAWKs4AAAAAAHNUnAEAAAAAQFmoOAMAAAAAzFFxBgAAAAAAZaHiDAAAAAAw5+HPcSZxBgAAAACYY6g2AAAAAAAoCxVnAAAAAIA5Ks4AAAAAAKAsVJwBAAAAAOa8PLvm6tlXDwAAAABAOag4AwAAAADMefjjqKg4AwAAAABggoozAAAAAMCch6+qTeIMAAAAADDn4YmzZ189AAAAAADloOIMAAAAADDH4mAAAAAAAKAsVJwBAAAAAOaY4wwAAAAAAMpCxRkAAAAAYI6KMwAAAAAAKAuJMwAAAADAnMWr6jYnzZ49W6GhofLx8VHXrl2VmZlZ5rGLFy9WVFSU6tSpI39/f0VERGjhwoVO90niDAAAAAAwZ7FU3eaE9PR0JSUlKSUlRRs2bFCnTp0UGxurAwcOlHp8vXr19Mgjj2jt2rX64YcflJCQoISEBH322WdO9UviDAAAAABwCzNnztSYMWOUkJCgdu3aae7cufLz89O8efNKPb5379666aab1LZtW4WFhenee+9Vx44d9dVXXznVL4kzAAAAAMBcFQ7VLigo0LFjxxy2goKCEiEUFhYqKytLMTEx9jYvLy/FxMRo7dq15V6CYRjKyMjQ9u3b1bNnT6cun8QZAAAAAOAyqampCgwMdNhSU1NLHJeXl6eioiIFBwc7tAcHBysnJ6fM8x89elS1atWS1WpV//79NWvWLF1zzTVOxcjjqAAAAAAA5qrwcVTJyclKSkpyaLPZbJV2/tq1a2vjxo06ceKEMjIylJSUpJYtW6p3794VPgeJMwAAAADAZWw2W4US5aCgIHl7eys3N9ehPTc3VyEhIWW+z8vLS61atZIkRUREaOvWrUpNTXUqcWaoNgAAAADAXDVYVdtqtSoyMlIZGRn2tuLiYmVkZCg6OrrC5ykuLi51DrUZKs4AAAAAALeQlJSk+Ph4RUVFqUuXLkpLS1N+fr4SEhIkSSNHjlSTJk3sc6RTU1MVFRWlsLAwFRQU6NNPP9XChQs1Z84cp/olcQYAAAAAmKvCOc7OiIuL08GDBzVx4kTl5OQoIiJCS5cutS8Ylp2dLS+v/4s1Pz9fd911l3799Vf5+voqPDxcr732muLi4pzql8QZAAAAAGCumiTOkpSYmKjExMRS961atcrh9WOPPabHHnvsvPusPlcPAAAAAEA1RMUZAAAAAGCuGlWcXcGzrx4AAAAAgHJQcQYAAAAAmPOq+GOjLkZUnAEAAAAAMEHFGQAAAABgjjnOAAAAAACgLFScAQAAAADmPLziTOIMAAAAADDn4YmzZ189AAAAAADluCgrziMifFwdgtv7Y89OV4fg1qZ/8purQ3B7E4qecnUIbs+rabirQ3Brk/vFujoEtxfkY7g6BLeWfcKzH/1SGTZ9y79nzlfUOz+5OgRUFxbP/p1ExRkAAAAAABMXZcUZAAAAAFCZqDgDAAAAAIAyUHEGAAAAAJhjVW0AAAAAAFAWKs4AAAAAAHMevqo2iTMAAAAAoByePVjZs68eAAAAAIByUHEGAAAAAJjz8KHaVJwBAAAAADBBxRkAAAAAYI6KMwAAAAAAKAsVZwAAAABAOTy75urZVw8AAAAAQDmoOAMAAAAAzHn4HGcSZwAAAACAOQ9PnBmqDQAAAACACSrOAAAAAIByeHbN1bOvHgAAAACAclBxBgAAAACYY44zAAAAAAAoCxVnAAAAAIA5i2fXXD376gEAAAAAKAcVZwAAAABAOTx7jjOJMwAAAADAHIuDAQAAAACAslBxBgAAAACYY3EwAAAAAABQFirOAAAAAABTFuY4AwAAAACAspA4AwAAAADK4VWFm3Nmz56t0NBQ+fj4qGvXrsrMzCzz2BdffFE9evRQ3bp1VbduXcXExJgeXxYSZwAAAACAW0hPT1dSUpJSUlK0YcMGderUSbGxsTpw4ECpx69atUrDhg3TypUrtXbtWjVt2lTXXnut9u3b51S/JM4AAAAAAHMWS5VtBQUFOnbsmMNWUFBQahgzZ87UmDFjlJCQoHbt2mnu3Lny8/PTvHnzSj3+9ddf11133aWIiAiFh4frpZdeUnFxsTIyMpy6fBJnAAAAAIDLpKamKjAw0GFLTU0tcVxhYaGysrIUExNjb/Py8lJMTIzWrl1bob5Onjyp06dPq169ek7FyKraAAAAAABzVbiqdnJyspKSkhzabDZbiePy8vJUVFSk4OBgh/bg4GBt27atQn099NBDaty4sUPyXREkzgAAAACAclTdYGWbzVZqolzZnnjiCb355ptatWqVfHx8nHoviTMAAAAAoNoLCgqSt7e3cnNzHdpzc3MVEhJi+t4nn3xSTzzxhJYvX66OHTs63TdznAEAAAAA5qpwcbCKslqtioyMdFjY6+xCX9HR0WW+73//+58effRRLV26VFFRUed0+VScAQAAAABuISkpSfHx8YqKilKXLl2Ulpam/Px8JSQkSJJGjhypJk2a2BcXmzZtmiZOnKhFixYpNDRUOTk5kqRatWqpVq1aFe6XxBkAAAAAYK4KFwdzRlxcnA4ePKiJEycqJydHERERWrp0qX3BsOzsbHl5/d/A6jlz5qiwsFD//Oc/Hc6TkpKiSZMmVbhfEmcAAAAAgNtITExUYmJiqftWrVrl8HrPnj2V0ieJMwAAAACgHJ69PJZnXz0AAAAAAOWg4gwAAAAAMFdN5ji7CokzAAAAAMCcxbMHK3v21QMAAAAAUA4qzgAAAACAcnj2UG0qzgAAAAAAmKDiDAAAAAAw5+GLg1FxBgAAAADABBVnAAAAAIA5VtUGAAAAAABloeIMAAAAADDn4XOcSZwBAAAAAOXw7MSZodoAAAAAAJig4gwAAAAAMOfhi4O5PHHeunWrvvnmG0VHRys8PFzbtm3T008/rYKCAo0YMUJ9+vQxfX9BQYEKCgoc24oM2bw9eygBAAAAAKByuPTPBkuXLlVERITGjRunzp07a+nSperZs6d27dqlvXv36tprr9WKFStMz5GamqrAwECHbdamwgt0BQAAAADgCSxVuFV/Lk2cp0yZogceeECHDh3S/Pnzdcstt2jMmDFatmyZMjIy9MADD+iJJ54wPUdycrKOHj3qsN3d3nqBrgAAAAAAcLFzaeK8efNmjRo1SpI0ZMgQHT9+XP/85z/t+4cPH64ffvjB9Bw2m00BAQEOG8O0AQAAAKASWSxVt7kBl8/wtvz/G+Xl5SUfHx8FBgba99WuXVtHjx51VWgAAAAAALg2cQ4NDdXOnTvtr9euXatmzZrZX2dnZ6tRo0auCA0AAAAAYOfZc5xduqr2nXfeqaKiIvvr9u3bO+xfsmRJuatqAwAAAACqmJsMqa4qLk2c77jjDtP9U6dOvUCRAAAAAABQOpfPcQYAAAAAoDojcQYAAAAAwIRLh2oDAAAAANyAh89xpuIMAAAAAIAJKs4AAAAAgHJQcQYAAAAAAGWg4gwAAAAAMOfhc5xJnAEAAAAA5fDsxJmh2gAAAAAAmKDiDAAAAAAw5+FDtak4AwAAAABggoozAAAAAKAcVJwBAAAAAEAZqDgDAAAAAMwxxxkAAAAAAJSFijMAAAAAoByeXXEmcQYAAAAAmGOoNgAAAAAA7mH27NkKDQ2Vj4+PunbtqszMzDKP3bx5s26++WaFhobKYrEoLS3tnPokcQYAAAAAlMNShVvFpaenKykpSSkpKdqwYYM6deqk2NhYHThwoNTjT548qZYtW+qJJ55QSEiIc5f8FyTOAAAAAAC3MHPmTI0ZM0YJCQlq166d5s6dKz8/P82bN6/U46+44gpNnz5dQ4cOlc1mO+d+SZwBAAAAAC5TUFCgY8eOOWwFBQUljissLFRWVpZiYmLsbV5eXoqJidHatWurNEYSZwAAAACAy6SmpiowMNBhS01NLXFcXl6eioqKFBwc7NAeHBysnJycKo2RVbUBAAAAAKYsVbiqdnJyspKSkhzazmdYdVUgcQYAAAAAuIzNZqtQohwUFCRvb2/l5uY6tOfm5p7Xwl8VwVBtAAAAAEA5XL+qttVqVWRkpDIyMuxtxcXFysjIUHR09PldXjmoOAMAAAAAzFXhUG1nJCUlKT4+XlFRUerSpYvS0tKUn5+vhIQESdLIkSPVpEkT+xzpwsJCbdmyxf7f+/bt08aNG1WrVi21atWqwv2SOAMAAAAA3EJcXJwOHjyoiRMnKicnRxEREVq6dKl9wbDs7Gx5ef3fwOrffvtNnTt3tr9+8skn9eSTT6pXr15atWpVhfslcQYAAAAAlKN6VJwlKTExUYmJiaXu+3syHBoaKsMwzrtP5jgDAAAAAGCCijMAAAAAwFw1mePsKlScAQAAAAAwQcUZAAAAAFAOKs4AAAAAAKAMVJwBAAAAAOY8fI4ziTMAAAAAoByenTgzVBsAAAAAABNUnAEAAAAA5jx8qDYVZwAAAAAATFBxBgAAAACUg4ozAAAAAAAoAxVnAAAAAIA5zy44U3EGAAAAAMAMFWcAAAAAQDk8u+RMxRkAAAAAABNUnAEAAAAA5jz8Oc4kzgAAAACAcnh24sxQbQAAAAAATFBxBgAAAACY8/Ch2lScAQAAAAAwQcUZAAAAAFAOKs4AAAAAAKAMFsMwDFcH4WkKCgqUmpqq5ORk2Ww2V4fjdrh/5497eH64f+ePe3j+uIfnh/t3/riH54f7d/64h7iQSJxd4NixYwoMDNTRo0cVEBDg6nDcDvfv/HEPzw/37/xxD88f9/D8cP/OH/fw/HD/zh/3EBcSQ7UBAAAAADBB4gwAAAAAgAkSZwAAAAAATJA4u4DNZlNKSgqLGJwj7t/54x6eH+7f+eMenj/u4fnh/p0/7uH54f6dP+4hLiQWBwMAAAAAwAQVZwAAAAAATJA4AwAAAABggsQZAAAAAAATJM4AAAAAAJggcb7AZs+erdDQUPn4+Khr167KzMx0dUhuY/Xq1RowYIAaN24si8Wi999/39UhuZXU1FRdccUVql27tho2bKiBAwdq+/btrg7LrcyZM0cdO3ZUQECAAgICFB0drSVLlrg6LLf1xBNPyGKx6L777nN1KG5j0qRJslgsDlt4eLirw3I7+/bt04gRI1S/fn35+vqqQ4cOWr9+vavDchuhoaElPocWi0Vjx451dWhuoaioSP/973/VokUL+fr6KiwsTI8++qhYr7fijh8/rvvuu0/NmzeXr6+vunXrpnXr1rk6LFzkSJwvoPT0dCUlJSklJUUbNmxQp06dFBsbqwMHDrg6NLeQn5+vTp06afbs2a4OxS198cUXGjt2rL755hstW7ZMp0+f1rXXXqv8/HxXh+Y2LrnkEj3xxBPKysrS+vXr1adPH914443avHmzq0NzO+vWrdPzzz+vjh07ujoUt3PZZZdp//799u2rr75ydUhu5ffff1f37t1Vs2ZNLVmyRFu2bNGMGTNUt25dV4fmNtatW+fwGVy2bJkkafDgwS6OzD1MmzZNc+bM0bPPPqutW7dq2rRp+t///qdZs2a5OjS3cdttt2nZsmVauHChfvzxR1177bWKiYnRvn37XB0aLmI8juoC6tq1q6644go9++yzkqTi4mI1bdpUd999t8aPH+/i6NyLxWLRe++9p4EDB7o6FLd18OBBNWzYUF988YV69uzp6nDcVr169TR9+nT961//cnUobuPEiRO6/PLL9dxzz+mxxx5TRESE0tLSXB2WW5g0aZLef/99bdy40dWhuK3x48fr66+/1pdffunqUC4a9913nz7++GPt3LlTFovF1eFUe9dff72Cg4P18ssv29tuvvlm+fr66rXXXnNhZO7hjz/+UO3atfXBBx+of//+9vbIyEj169dPjz32mAujw8WMivMFUlhYqKysLMXExNjbvLy8FBMTo7Vr17owMniqo0ePSvoz8YPzioqK9Oabbyo/P1/R0dGuDsetjB07Vv3793f4fYiK27lzpxo3bqyWLVtq+PDhys7OdnVIbuXDDz9UVFSUBg8erIYNG6pz58568cUXXR2W2yosLNRrr72m0aNHkzRXULdu3ZSRkaEdO3ZIkr7//nt99dVX6tevn4sjcw9nzpxRUVGRfHx8HNp9fX0ZgYMqVcPVAXiKvLw8FRUVKTg42KE9ODhY27Ztc1FU8FTFxcW677771L17d7Vv397V4biVH3/8UdHR0Tp16pRq1aql9957T+3atXN1WG7jzTff1IYNG5iLdo66du2qBQsWqE2bNtq/f78mT56sHj16aNOmTapdu7arw3MLP//8s+bMmaOkpCQ9/PDDWrdune655x5ZrVbFx8e7Ojy38/777+vIkSMaNWqUq0NxG+PHj9exY8cUHh4ub29vFRUV6fHHH9fw4cNdHZpbqF27tqKjo/Xoo4+qbdu2Cg4O1htvvKG1a9eqVatWrg4PFzESZ8ADjR07Vps2beIvs+egTZs22rhxo44ePap33nlH8fHx+uKLL0ieK+CXX37Rvffeq2XLlpWoFKBi/lqR6tixo7p27armzZvrrbfeYrpABRUXFysqKkpTp06VJHXu3FmbNm3S3LlzSZzPwcsvv6x+/fqpcePGrg7Fbbz11lt6/fXXtWjRIl122WXauHGj7rvvPjVu3JjPYAUtXLhQo0ePVpMmTeTt7a3LL79cw4YNU1ZWlqtDw0WMxPkCCQoKkre3t3Jzcx3ac3NzFRIS4qKo4IkSExP18ccfa/Xq1brkkktcHY7bsVqt9r9oR0ZGat26dXr66af1/PPPuziy6i8rK0sHDhzQ5Zdfbm8rKirS6tWr9eyzz6qgoEDe3t4ujND91KlTR61bt9auXbtcHYrbaNSoUYk/dLVt21bvvvuuiyJyX3v37tXy5cu1ePFiV4fiVh544AGNHz9eQ4cOlSR16NBBe/fuVWpqKolzBYWFhemLL75Qfn6+jh07pkaNGikuLk4tW7Z0dWi4iDHH+QKxWq2KjIxURkaGva24uFgZGRnMj8QFYRiGEhMT9d5772nFihVq0aKFq0O6KBQXF6ugoMDVYbiFvn376scff9TGjRvtW1RUlIYPH66NGzeSNJ+DEydO6KefflKjRo1cHYrb6N69e4lH8e3YsUPNmzd3UUTua/78+WrYsKHDAk0o38mTJ+Xl5fhPcG9vbxUXF7soIvfl7++vRo0a6ffff9dnn32mG2+80dUh4SJGxfkCSkpKUnx8vKKiotSlSxelpaUpPz9fCQkJrg7NLZw4ccKhqrJ7925t3LhR9erVU7NmzVwYmXsYO3asFi1apA8++EC1a9dWTk6OJCkwMFC+vr4ujs49JCcnq1+/fmrWrJmOHz+uRYsWadWqVfrss89cHZpbqF27dok59f7+/qpfvz5z7Sto3LhxGjBggJo3b67ffvtNKSkp8vb21rBhw1wdmtu4//771a1bN02dOlVDhgxRZmamXnjhBb3wwguuDs2tFBcXa/78+YqPj1eNGvxz0hkDBgzQ448/rmbNmumyyy7Td999p5kzZ2r06NGuDs1tfPbZZzIMQ23atNGuXbv0wAMPKDw8nH9To2oZuKBmzZplNGvWzLBarUaXLl2Mb775xtUhuY2VK1cakkps8fHxrg7NLZR27yQZ8+fPd3VobmP06NFG8+bNDavVajRo0MDo27ev8fnnn7s6LLfWq1cv495773V1GG4jLi7OaNSokWG1Wo0mTZoYcXFxxq5du1wdltv56KOPjPbt2xs2m80IDw83XnjhBVeH5HY+++wzQ5Kxfft2V4fido4dO2bce++9RrNmzQwfHx+jZcuWxiOPPGIUFBS4OjS3kZ6ebrRs2dKwWq1GSEiIMXbsWOPIkSOuDgsXOZ7jDAAAAACACeY4AwAAAABggsQZAAAAAAATJM4AAAAAAJggcQYAAAAAwASJMwAAAAAAJkicAQAAAAAwQeIMAAAAAIAJEmcAAAAAAEyQOAMA4ITQ0FClpaW5OgwAAHABkTgDAKqtUaNGaeDAgZKk3r1767777rtgfS9YsEB16tQp0b5u3TrdfvvtFywOAADgejVcHQAAABdSYWGhrFbrOb+/QYMGlRgNAABwB1ScAQDV3qhRo/TFF1/o6aeflsVikcVi0Z49eyRJmzZtUr9+/VSrVi0FBwfr1ltvVV5env29vXv3VmJiou677z4FBQUpNjZWkjRz5kx16NBB/v7+atq0qe666y6dOHFCkrRq1SolJCTo6NGj9v4mTZokqeRQ7ezsbN14442qVauWAgICNGTIEOXm5tr3T5o0SREREVq4cKFCQ0MVGBiooUOH6vjx4/Zj3nnnHXXo0EG+vr6qX7++YmJilJ+fX0V3EwAAOIvEGQBQ7T399NOKjo7WmDFjtH//fu3fv19NmzbVkSNH1KdPH3Xu3Fnr16/X0qVLlZubqyFDhji8/5VXXpHVatXXX3+tuXPnSpK8vLz0zDPPaPPmzXrllVe0YsUKPfjgg5Kkbt26KS0tTQEBAfb+xo0bVyKu4uJi3XjjjTp8+LC++OILLVu2TD///LPi4uIcjvvpp5/0/vvv6+OPP9bHH3+sL774Qk888YQkaf/+/Ro2bJhGjx6trVu3atWqVRo0aJAMw6iKWwkAAM4BQ7UBANVeYGCgrFar/Pz8FBISYm9/9tln1blzZ02dOtXeNm/ePDVt2lQ7duxQ69atJUmXXnqp/ve//zmc86/zpUNDQ/XYY4/pjjvu0HPPPSer1arAwEBZLBaH/v4uIyNDP/74o3bv3q2mTZtKkl599VVddtllWrduna644gpJfybYCxYsUO3atSVJt956qzIyMvT4449r//79OnPmjAYNGqTmzZtLkjp06HAedwsAAFQ2Ks4AALf1/fffa+XKlapVq5Z9Cw8Pl/RnlfesyMjIEu9dvny5+vbtqyZNmqh27dq69dZbdejQIZ08ebLC/W/dulVNmza1J82S1K5dO9WpU0dbt261t4WGhtqTZklq1KiRDhw4IEnq1KmT+vbtqw4dOmjw4MF68cUX9fvvv1f8JgAAgCpH4gwAcFsnTpzQgAEDtHHjRodt586d6tmzp/04f39/h/ft2bNH119/vTp27Kh3331XWVlZmj17tqQ/Fw+rbDVr1nR4bbFYVFxcLEny9vbWsmXLtGTJErVr106zZs1SmzZttHv37kqPAwAAnBsSZwCAW7BarSoqKnJou/zyy7V582aFhoaqVatWDtvfk+W/ysrKUnFxsWbMmKErr7xSrVu31m+//VZuf3/Xtm1b/fLLL/rll1/sbVu2bNGRI0fUrl27Cl+bxWJR9+7dNXnyZH333XeyWq167733Kvx+AABQtUicAQBuITQ0VN9++6327NmjvLw8FRcXa+zYsTp8+LCGDRumdevW6aefftJnn32mhIQE06S3VatWOn36tGbNmqWff/5ZCxcutC8a9tf+Tpw4oYyMDOXl5ZU6hDsmJkYdOnTQ8OHDtWHDBmVmZmrkyJHq1auXoqKiKnRd3377raZOnar169crOztbixcv1sGDB9W2bVvnbhAAAKgyJM4AALcwbtw4eXt7q127dmrQoIGys7PVuHFjff311yoqKtK1116rDh066L777lOdOnXk5VX2/8V16tRJM2fO1LRp09S+fXu9/vrrSk1NdTimW7duuuOOOxQXF6cGDRqUWFxM+rNS/MEHH6hu3brq2bOnYmJi1LJlS6Wnp1f4ugICArR69Wpdd911at26tSZMmKAZM2aoX79+Fb85AACgSlkMnncBAAAAAECZqDgDAAAAAGCCxBkAAAAAABMkzgAAAAAAmCBxBgAAAADABIkzAAAAAAAmSJwBAAAAADBB4gwAAAAAgAkSZwAAAAAATJA4AwAAAABggsQZAAAAAAATJM4AAAAAAJj4fy50tyXhYb9wAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1300x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Re-importing libraries since the environment was reset\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Re-defining the new given tensors\n",
        "data = [\n",
        "    torch.tensor([0.3280, 0.6865, 0.8994, 0.6470]),\n",
        "    torch.tensor([0.2027, 0.7614, 0.4756, 0.5733]),\n",
        "    torch.tensor([0.3277, 0.6425, 0.4990, 0.9358]),\n",
        "    torch.tensor([0.0425, 0.5838, 0.2589, 0.5078]),\n",
        "    torch.tensor([0.8846, 0.3652, 0.4327, 0.4097]),\n",
        "    torch.tensor([0.3963, 0.8119, 0.1985, 0.9376]),\n",
        "    torch.tensor([0.8370, 0.0837, 0.9096, 0.8794]),\n",
        "    torch.tensor([0.2446, 0.6766, 0.8469, 0.9327]),\n",
        "    torch.tensor([0.5060, 0.2740, 0.5478, 0.7448]),\n",
        "    torch.tensor([0.5537, 0.4535, 0.5387, 0.0897])\n",
        "]\n",
        "\n",
        "# Combine into a 4x10 matrix\n",
        "matrix = torch.stack(data, dim=1).numpy()\n",
        "\n",
        "# Plotting the heatmap without annotations on the grid cells\n",
        "plt.figure(figsize=(13, 6))\n",
        "\n",
        "# Using a warm color map and keeping the 10 rows by 4 columns structure\n",
        "sns.heatmap(matrix, annot=False, cmap='Oranges', cbar=True)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.title('Heatmap of Latent Values over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Latent Values')\n",
        "\n",
        "# Display the heatmap\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
